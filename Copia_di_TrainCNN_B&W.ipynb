{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/pietrodileo/Python_for_MD_thesis/blob/main/Copia_di_TrainCNN_B%26W.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5D_LUG6ajBr6"
      },
      "source": [
        "# 1. üöÄ Install, Import, Login"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k4dCH_UCpzF6"
      },
      "source": [
        "Setup for W&B Tool"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "EF0A0Yd4dQw6"
      },
      "outputs": [],
      "source": [
        "# Install a pip package in the current Jupyter kernel\n",
        "# import sys\n",
        "# !{sys.executable} -m pip install wandb\n",
        "# import wandb\n",
        "# from wandb.keras import WandbCallback\n",
        "## 075552994aad288a1162d4ab06f96040112fd54c\n",
        "# wandb.login()\n",
        "\n",
        "# wandb.init()\n",
        "# config = wandb.config"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QICVulkAp2WH"
      },
      "source": [
        "Import Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "Rzb8hEseZL0d"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "import wave\n",
        "import pylab\n",
        "import sys\n",
        "from pathlib import Path\n",
        "from scipy import signal\n",
        "from scipy.io import wavfile\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from keras.utils.vis_utils import plot_model\n",
        "import itertools\n",
        "import time\n",
        "import shutil\n",
        "import plotly.express as px\n",
        "import plotly.graph_objects as go\n",
        "from plotly.subplots import make_subplots"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install aspose-words\n",
        "import aspose.words as aw"
      ],
      "metadata": {
        "id": "Pd-3ktNDEWpn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "98f4edf5-a42e-49d6-99b3-203baee568e7"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: aspose-words in /usr/local/lib/python3.7/dist-packages (22.10.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# # To save static image with plotly\n",
        "# %%capture\n",
        "# !pip install kaleido\n",
        "# !pip install plotly>=4.0.0\n",
        "# !wget https://github.com/plotly/orca/releases/download/v1.2.1/orca-1.2.1-x86_64.AppImage -O /usr/local/bin/orca\n",
        "# !chmod +x /usr/local/bin/orca\n",
        "# !apt-get install xvfb libgtk2.0-0 libgconf-2-4"
      ],
      "metadata": {
        "id": "TsQWNv1D9eeK"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -U kaleido\n",
        "#need to restart runtime after install kaleido\n",
        "import kaleido\n",
        "import plotly.express as px"
      ],
      "metadata": {
        "id": "HsMikjLATdcW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7c1392ca-8d46-4413-969e-34e9fc218194"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: kaleido in /usr/local/lib/python3.7/dist-packages (0.2.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lh3M28Qsp4qf"
      },
      "source": [
        "Calculate execution time"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "5wRUqDOupwVY"
      },
      "outputs": [],
      "source": [
        "start_time = time.time()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0-Kj8LW0Pll-"
      },
      "source": [
        "## 2. Preparing the data\n",
        "We can now load the spectrograms into memory. We use the image_dataset_from_directory utility to generate the datasets, and we use Keras image preprocessing layers for image standardization and data augmentation. The validation set is what will ultimately be our benchmark when becomes to performance and accuracy of our classifier. The batch size is set fairly low for now (32) for all images to fit in memory. The seed is for reproducibility."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "oM3R5Fh0PIbK"
      },
      "outputs": [],
      "source": [
        "def createTrain_and_Test_Dataset(directory,BATCH_SIZE,VAL_SPLIT,IMAGE_HEIGHT, IMAGE_WIDTH, MODE):\n",
        "  # Make a dataset containing the training spectrograms\n",
        "  train_dataset = tf.keras.preprocessing.image_dataset_from_directory(\n",
        "                                            directory,\n",
        "                                            labels='inferred',\n",
        "                                            batch_size=BATCH_SIZE,\n",
        "                                            validation_split=VAL_SPLIT,\n",
        "                                            subset='training',\n",
        "                                            shuffle=True,\n",
        "                                            color_mode= MODE,\n",
        "                                            image_size=(IMAGE_HEIGHT, IMAGE_WIDTH),\n",
        "                                            seed=0)\n",
        "\n",
        "  # Make a dataset containing the validation spectrogram\n",
        "  valid_dataset = tf.keras.preprocessing.image_dataset_from_directory(\n",
        "                                            directory,\n",
        "                                            labels='inferred',\n",
        "                                            batch_size=BATCH_SIZE,\n",
        "                                            validation_split=VAL_SPLIT,\n",
        "                                            subset='validation',\n",
        "                                            shuffle=True,\n",
        "                                            color_mode= MODE,\n",
        "                                            image_size=(IMAGE_HEIGHT, IMAGE_WIDTH),\n",
        "                                            seed=0)\n",
        "  return train_dataset, valid_dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xHtsnmb6Prhi"
      },
      "source": [
        "Before we can build our model and start training, we need to apply one simple augmentation the dataset and that is rescaling. We convert input from int to float32 and rescale it from the (0, 255) range to the (0,1) range."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "DU_FcEUaP26F"
      },
      "outputs": [],
      "source": [
        "# Function to prepare our datasets for modelling\n",
        "def prepare(ds, augment=False):\n",
        "    # Define our one transformation\n",
        "    rescale = tf.keras.Sequential([tf.keras.layers.experimental.preprocessing.Rescaling(1./255)])\n",
        "    \n",
        "    flip_and_rotate = tf.keras.Sequential([\n",
        "        tf.keras.layers.experimental.preprocessing.RandomFlip(\"horizontal_and_vertical\"),\n",
        "        tf.keras.layers.experimental.preprocessing.RandomRotation(0.2)\n",
        "    ])\n",
        "\n",
        "    # Apply rescale to both datasets and augmentation only to training\n",
        "    ds = ds.map(lambda x, y: (rescale(x, training=True), y))\n",
        "    # if augment == True, do ImageAugmentation\n",
        "    if augment: \n",
        "      ds = ds.map(lambda x, y: (flip_and_rotate(x, training=True), y))\n",
        "    return ds"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I-L4Yt1djL5g"
      },
      "source": [
        "# 2. üß† Define the Model and Train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "5F8bXADMjRZi"
      },
      "outputs": [],
      "source": [
        "def make_model(IMAGE_HEIGHT, IMAGE_WIDTH, N_CHANNELS, N_CLASSES):\n",
        "  # Create CNN model with 3 Convolution Layer Architecture\n",
        "  model = tf.keras.models.Sequential()\n",
        "  model.add(tf.keras.layers.Input(shape=(IMAGE_HEIGHT, IMAGE_WIDTH, N_CHANNELS)))\n",
        "  # Conv2D(NumFilter, FilterSize, option...)\n",
        "  model.add(tf.keras.layers.Conv2D(32, (3, 3), strides=2, padding='same', activation='relu')) #kernel_initializer='he_uniform'\n",
        "  model.add(tf.keras.layers.BatchNormalization())\n",
        "  model.add(tf.keras.layers.MaxPooling2D(pool_size=(2, 2)))\n",
        "  model.add(tf.keras.layers.BatchNormalization())\n",
        "  model.add(tf.keras.layers.Conv2D(64, (3, 3), padding='same', activation='relu'))\n",
        "  model.add(tf.keras.layers.BatchNormalization())\n",
        "  model.add(tf.keras.layers.MaxPooling2D(pool_size=(2, 2)))\n",
        "  model.add(tf.keras.layers.BatchNormalization())\n",
        "  model.add(tf.keras.layers.Conv2D(128, (3, 3), padding='same', activation='relu'))\n",
        "  model.add(tf.keras.layers.BatchNormalization())\n",
        "  model.add(tf.keras.layers.MaxPooling2D(pool_size=(2, 2)))\n",
        "  model.add(tf.keras.layers.BatchNormalization())\n",
        "  model.add(tf.keras.layers.Conv2D(256, (3, 3), padding='same', activation='relu'))\n",
        "  model.add(tf.keras.layers.BatchNormalization())\n",
        "  model.add(tf.keras.layers.MaxPooling2D(pool_size=(2, 2)))\n",
        "  model.add(tf.keras.layers.BatchNormalization())\n",
        "  model.add(tf.keras.layers.Flatten())\n",
        "  model.add(tf.keras.layers.Dense(256, activation='relu')) \n",
        "  model.add(tf.keras.layers.BatchNormalization())\n",
        "  model.add(tf.keras.layers.Dropout(0.5))\n",
        "  model.add(tf.keras.layers.Dense(N_CLASSES, activation='softmax'))\n",
        "  return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "_uV7Gp_1QDJi"
      },
      "outputs": [],
      "source": [
        "# def plotResults(history,SaveFile,outputPath):\n",
        "#   # Plot the loss curves for training and validation.\n",
        "#   history_dict = history.history\n",
        "#   loss_values = history_dict['loss']\n",
        "#   val_loss_values = history_dict['val_loss']\n",
        "#   epochs = range(1, len(loss_values)+1)\n",
        "\n",
        "#   plt.figure(figsize=(10,15))\n",
        "#   plt.subplot(211)\n",
        "#   plt.plot(epochs, loss_values, 'g', label='Training loss')\n",
        "#   plt.plot(epochs, loss_values, 'go')\n",
        "#   plt.plot(epochs, val_loss_values, 'b', label='Validation loss')\n",
        "#   plt.plot(epochs, val_loss_values, 'bo')\n",
        "#   plt.title('Training and validation loss')\n",
        "#   plt.xlabel('Epochs')\n",
        "#   plt.ylabel('Loss')\n",
        "#   plt.legend()\n",
        "#   plt.show()\n",
        "\n",
        "#   # Plot the accuracy curves for training and validation.\n",
        "#   acc_values = history_dict['accuracy']\n",
        "#   val_acc_values = history_dict['val_accuracy']\n",
        "#   epochs = range(1, len(acc_values)+1)\n",
        "\n",
        "#   plt.figure(figsize=(10,15))\n",
        "#   plt.subplot(221)\n",
        "#   plt.plot(epochs, acc_values, 'g', label='Training accuracy')\n",
        "#   plt.plot(epochs, acc_values, 'go')\n",
        "#   plt.plot(epochs, val_acc_values, 'b', label='Validation accuracy')\n",
        "#   plt.plot(epochs, val_acc_values, 'bo')\n",
        "#   plt.title('Training and validation accuracy')\n",
        "#   plt.xlabel('Epochs')\n",
        "#   plt.ylabel('Accuracy')\n",
        "#   plt.legend()\n",
        "#   plt.show()\n",
        "\n",
        "#   if SaveFile == True:\n",
        "#     AccLossPngOutput = os.path.join(outputPath,'results.png')\n",
        "#     plt.savefig(AccLossPngOutput, bbox_inches='tight')\n",
        "#     plt.close()\n",
        "#     print('Image Saved')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def plotResults(history,SaveFile,outputPath):\n",
        "  # Plot the loss curves for training and validation.\n",
        "  history_dict = history.history\n",
        "  loss_values = history_dict['loss']\n",
        "  val_loss_values = history_dict['val_loss']\n",
        "  epochs = range(1, len(loss_values)+1)\n",
        "  \n",
        "  d = {'Train Loss': loss_values, 'Test Loss': val_loss_values, 'Epochs':epochs}\n",
        "  df = pd.DataFrame(d)\n",
        "  \n",
        "  fig = go.Figure()\n",
        "  fig = make_subplots(rows=2, cols=1,\n",
        "                      subplot_titles=(\"Training and Validation Loss\", \"Training and Validation Accuracy\"))\n",
        "\n",
        "  fig.append_trace(go.Scatter(\n",
        "      x=df['Epochs'],\n",
        "      y=df['Train Loss'],\n",
        "      name=\"Training Loss\",       # this sets its legend entry\n",
        "      mode='lines+markers'\n",
        "  ),1,1),\n",
        "\n",
        "  fig.append_trace(go.Scatter(\n",
        "      x=df['Epochs'],\n",
        "      y=df['Test Loss'],\n",
        "      name=\"Validation Loss\",\n",
        "      mode='lines+markers'\n",
        "  ),1,1),\n",
        "\n",
        "  # Plot the accuracy curves for training and validation.\n",
        "  acc_values = history_dict['accuracy']\n",
        "  val_acc_values = history_dict['val_accuracy']\n",
        "  epochs = range(1, len(acc_values)+1)\n",
        "\n",
        "  d = {'Train Accuracy': acc_values, 'Test Accuracy': val_acc_values, 'Epochs':epochs}\n",
        "  df = pd.DataFrame(d)\n",
        "\n",
        "  fig.append_trace(go.Scatter(\n",
        "      x=df['Epochs'],\n",
        "      y=df['Train Accuracy'],\n",
        "      name=\"Training Accuracy\",       # this sets its legend entry\n",
        "      mode='lines+markers'\n",
        "  ),2,1),\n",
        "\n",
        "  fig.append_trace(go.Scatter(\n",
        "      x=df['Epochs'],\n",
        "      y=df['Test Accuracy'],\n",
        "      name=\"Validation Accuracy\",\n",
        "      mode='lines+markers'\n",
        "  ),2,1),\n",
        "\n",
        "  # edit axis labels\n",
        "  fig['layout']['xaxis']['title']='Epochs'\n",
        "  fig['layout']['xaxis2']['title']='Epochs'\n",
        "  fig['layout']['yaxis']['title']='Loss'\n",
        "  fig['layout']['yaxis2']['title']='Accuracy'\n",
        "\n",
        "  # Tick Distance\n",
        "  fig['layout']['xaxis']['dtick']= 5\n",
        "  fig['layout']['xaxis2']['dtick']= 5\n",
        "  # First value on x axis\n",
        "  fig['layout']['xaxis']['tick0']= 0\n",
        "  fig['layout']['xaxis2']['tick0']= 0\n",
        "  # Tick Mode\n",
        "  fig['layout']['xaxis']['tickmode']= 'linear'\n",
        "  fig['layout']['xaxis2']['tickmode']= 'linear'\n",
        "\n",
        "  fig.update_layout(\n",
        "      height=800, \n",
        "      width=1200,\n",
        "      title=\"Loss and Accuracy\",\n",
        "      legend_title=\"Dataset\",\n",
        "      font=dict(size=14)\n",
        "  )\n",
        "\n",
        "  return fig, loss_values, val_loss_values, acc_values, val_acc_values"
      ],
      "metadata": {
        "id": "RpGQiSXAqHFw"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mt_EXMHB1aoy"
      },
      "source": [
        "# 3. üíØ Compute Code"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z64G6e4vSboI"
      },
      "source": [
        "Define Input and Output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "4cYlgi69qoJz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ff58df38-3e66-4cc4-b8ba-0846099a794c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The output folder has been created!\n"
          ]
        }
      ],
      "source": [
        "TASK = '60EP_full_4Conv_Batch128'\n",
        "directory = '/content/drive/MyDrive/DatasetTesi/outputSpectrogram/Mel-Spectrogram/provaClass_PDoffDbs_VS_HS'\n",
        "outputPath = '/content/drive/MyDrive/DatasetTesi/outputSpectrogram/Mel-Spectrogram/Risultati_PDoffDbs_VS_HS'\n",
        "outputPath = os.path.join(outputPath,TASK)\n",
        "\n",
        "if not os.path.exists(outputPath):\n",
        "   # Create a new directory because it does not exist\n",
        "   os.makedirs(outputPath)\n",
        "   print(\"The output folder has been created!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6v7ePYXsSfCp"
      },
      "source": [
        "Define Parameters for Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "NEzN4dZhSeFV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "15cf7b2a-f07c-44a8-c473-07e7c59b600c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 1816 files belonging to 2 classes.\n",
            "Using 1453 files for training.\n",
            "Found 1816 files belonging to 2 classes.\n",
            "Using 363 files for validation.\n"
          ]
        }
      ],
      "source": [
        "# Declare constants\n",
        "IMAGE_HEIGHT = 256\n",
        "IMAGE_WIDTH = 256\n",
        "BATCH_SIZE = 128 # 8, 16, 32, 64, 128, 256\n",
        "N_CHANNELS = 1 # RGB = 3, BW = 1\n",
        "EPOCHS = 60\n",
        "VAL_SPLIT = 0.2\n",
        "MODE = 'grayscale' #rgb, rgba or grayscale, convert the image to have 1, 3 or 4 channels\n",
        "SaveFile = True\n",
        "\n",
        "[train_dataset, valid_dataset] = createTrain_and_Test_Dataset(directory,BATCH_SIZE,VAL_SPLIT,IMAGE_HEIGHT, IMAGE_WIDTH, MODE)\n",
        "\n",
        "classNames = train_dataset.class_names\n",
        "N_CLASSES = len(classNames)\n",
        "\n",
        "train_dataset = prepare(train_dataset, augment=False)\n",
        "valid_dataset = prepare(valid_dataset, augment=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ELEmc60XS1m-"
      },
      "source": [
        "Make Model and Plot Results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sjKWPceKkTFb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1a1275e0-77a6-46b0-e5d2-29eb03125e36"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/60\n",
            "12/12 [==============================] - 203s 10s/step - loss: 1.0273 - accuracy: 0.6800 - val_loss: 0.7065 - val_accuracy: 0.4628\n",
            "Epoch 2/60\n",
            "12/12 [==============================] - 126s 8s/step - loss: 0.6232 - accuracy: 0.7481 - val_loss: 1.2257 - val_accuracy: 0.4628\n",
            "Epoch 3/60\n",
            "12/12 [==============================] - 126s 8s/step - loss: 0.4679 - accuracy: 0.8018 - val_loss: 1.0028 - val_accuracy: 0.4628\n",
            "Epoch 4/60\n",
            "12/12 [==============================] - 127s 8s/step - loss: 0.4665 - accuracy: 0.8121 - val_loss: 1.9466 - val_accuracy: 0.4628\n",
            "Epoch 5/60\n",
            "12/12 [==============================] - 125s 8s/step - loss: 0.3780 - accuracy: 0.8513 - val_loss: 2.6332 - val_accuracy: 0.4628\n",
            "Epoch 6/60\n",
            "12/12 [==============================] - 126s 8s/step - loss: 0.3314 - accuracy: 0.8692 - val_loss: 0.9925 - val_accuracy: 0.4628\n",
            "Epoch 7/60\n",
            "12/12 [==============================] - 126s 8s/step - loss: 0.3375 - accuracy: 0.8741 - val_loss: 0.7168 - val_accuracy: 0.5372\n",
            "Epoch 8/60\n",
            "12/12 [==============================] - 127s 8s/step - loss: 0.2317 - accuracy: 0.9098 - val_loss: 0.7514 - val_accuracy: 0.4628\n",
            "Epoch 9/60\n",
            " 8/12 [===================>..........] - ETA: 29s - loss: 0.2089 - accuracy: 0.9189"
          ]
        }
      ],
      "source": [
        "# wandb.config = {\n",
        "#   \"learning_rate\": 0.001,\n",
        "#   \"epochs\": EPOCHS,\n",
        "#   \"batch_size\": BATCH_SIZE,\n",
        "#   \"architecture\": \"CNN\"\n",
        "# }\n",
        "\n",
        "model = make_model(IMAGE_HEIGHT, IMAGE_WIDTH, N_CHANNELS, N_CLASSES)\n",
        "\n",
        "# Compile model\n",
        "model.compile(\n",
        "    loss='sparse_categorical_crossentropy',\n",
        "    optimizer=tf.keras.optimizers.RMSprop(),\n",
        "    metrics=['accuracy'],\n",
        ")\n",
        "\n",
        "# wandb.init()\n",
        "\n",
        "# Train model and capture the history\n",
        "history = model.fit(train_dataset, epochs=EPOCHS, validation_data=valid_dataset)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "fig, loss_values, val_loss_values, acc_values, val_acc_values = plotResults(history,SaveFile,outputPath)\n",
        "fig.show()"
      ],
      "metadata": {
        "id": "GcZCdu8qoXdd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Save pic in HTML\n",
        "if SaveFile == True:\n",
        "  AccLossPngOutput = os.path.join(outputPath,'results.html')\n",
        "  fig.write_html(AccLossPngOutput)\n",
        "  print('Image Saved')"
      ],
      "metadata": {
        "id": "wnMBGtUzDVHr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert HTML in PNG and export to Google Drive\n",
        "resultImg = f\"{outputPath}\"+'/results.png'\n",
        "fig.to_image(format=\"png\", engine=\"kaleido\");\n",
        "fig.write_image(resultImg)"
      ],
      "metadata": {
        "id": "ZOm5LjC4c346"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "psSaogYhS94c"
      },
      "source": [
        "Export Results to Google Drive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jOmJcmE4eVTE"
      },
      "outputs": [],
      "source": [
        "# ‚≠ê: log metrics using wandb.log\n",
        "# wandb.log({'epochs': EPOCHS,\n",
        "#            'loss': loss_values,\n",
        "#            'acc': acc_values, \n",
        "#            'val_loss': val_loss_values,\n",
        "#            'val_acc':val_acc_values})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1wZf15D4QHVy"
      },
      "outputs": [],
      "source": [
        "# Compute the final loss and accuracy\n",
        "final_loss, final_acc = model.evaluate(valid_dataset, verbose=0)\n",
        "print(\"Final loss: {0:.6f}, final accuracy: {1:.6f}\".format(final_loss, final_acc))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kGIMxaGmYvsM"
      },
      "outputs": [],
      "source": [
        "runtime = time.time() - start_time\n",
        "\n",
        "print('Runtime:')\n",
        "print(\"--- %s seconds ---\" % (runtime))\n",
        "print(\"--- %s minutes ---\" % ((runtime)/60))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "68lcys2S5p9E"
      },
      "outputs": [],
      "source": [
        "# dictionary of lists  \n",
        "InfoDict = {'IMAGE_HEIGHT':[IMAGE_HEIGHT], 'IMAGE_WIDTH':[IMAGE_WIDTH],\n",
        "              'BATCH_SIZE': [BATCH_SIZE], 'N_CHANNELS': [N_CHANNELS], 'N_CLASSES': [N_CLASSES],\n",
        "              'EPOCHS':[EPOCHS], 'VAL_SPLIT': [VAL_SPLIT], 'MODE': MODE,\n",
        "              'FINAL VALIDATION LOSS': [final_loss], 'FINAL VALIDATION ACC': [final_acc],\n",
        "              'RUNTIME (s)': [runtime], 'RUNTIME (min)': [runtime/60]\n",
        "              }\n",
        "InfoDict\n",
        "dfInfo = pd.DataFrame(InfoDict)\n",
        "dfInfo.index = ['CNN']\n",
        "# saving the dataframe \n",
        "outputName = 'Model_Info_and_Performance.xlsx'\n",
        "OutputFileName = os.path.join(outputPath,outputName)\n",
        "if SaveFile == True:\n",
        "  # writing to Excel\n",
        "  dfInfo.to_excel(OutputFileName)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g4K3KSjgzu7C"
      },
      "outputs": [],
      "source": [
        "# dictionary of lists  \n",
        "OutputDict = {'Train_ACC':acc_values, 'Train_LOSS':loss_values, \n",
        "              'Test_ACC': val_acc_values, 'Test_LOSS': val_loss_values}\n",
        "dfResult = pd.DataFrame(OutputDict) \n",
        "# saving the dataframe \n",
        "outputName = 'Risultati'\n",
        "OutputFileName = outputPath+'/'+outputName+'.xlsx'\n",
        "dfResult.to_excel(OutputFileName) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CJnUc6p7ll4Z"
      },
      "outputs": [],
      "source": [
        "Summary = os.path.join(outputPath,'modelsummary.txt')\n",
        "modelInfo = model.summary()\n",
        "\n",
        "stringlist = []\n",
        "model.summary(print_fn=lambda x: stringlist.append(x))\n",
        "short_model_summary = \"\\n\".join(stringlist)\n",
        "print(short_model_summary)\n",
        "\n",
        "with open(Summary, 'w') as f:\n",
        "  # Pass the file handle in as a lambda function to make it callable\n",
        "  f.write(short_model_summary)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FYy0getAmjMT"
      },
      "outputs": [],
      "source": [
        "pngOutput = os.path.join(outputPath,'model_plot.png')\n",
        "plot_model(model, to_file=pngOutput, show_shapes=True, show_layer_names=False)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "provenance": [],
      "mount_file_id": "1UTLBRk3vikR0G6J08UtrzMlSM0jEMLoE",
      "authorship_tag": "ABX9TyNNLCiC4XsnDCw5XSONX9i3",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}