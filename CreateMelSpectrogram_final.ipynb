{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/pietrodileo/Python_for_MD_thesis/blob/main/CreateMelSpectrogram_final.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4v0ytLlfkqPe"
      },
      "source": [
        "# 🔊 **Audio Signal Visualization** \n",
        "## Generate easily different plot from audio signals stored in Google Drive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 366,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KK7-L87_4MWI",
        "outputId": "f2a364ce-4ba0-4700-9de2-a68dc4e9198c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "75sL32jtmAjS"
      },
      "source": [
        "## Import libraries 📚"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 367,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LuPxg6GVwA9r",
        "outputId": "d7dcf01b-ef95-43dd-e8b6-a67d2928e273"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: audiomentations in /usr/local/lib/python3.7/dist-packages (0.27.0)\n",
            "Requirement already satisfied: librosa<0.10.0,>0.7.2 in /usr/local/lib/python3.7/dist-packages (from audiomentations) (0.8.1)\n",
            "Requirement already satisfied: numpy>=1.13.0 in /usr/local/lib/python3.7/dist-packages (from audiomentations) (1.21.6)\n",
            "Requirement already satisfied: scipy<2,>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from audiomentations) (1.7.3)\n",
            "Requirement already satisfied: numba>=0.43.0 in /usr/local/lib/python3.7/dist-packages (from librosa<0.10.0,>0.7.2->audiomentations) (0.56.4)\n",
            "Requirement already satisfied: pooch>=1.0 in /usr/local/lib/python3.7/dist-packages (from librosa<0.10.0,>0.7.2->audiomentations) (1.6.0)\n",
            "Requirement already satisfied: joblib>=0.14 in /usr/local/lib/python3.7/dist-packages (from librosa<0.10.0,>0.7.2->audiomentations) (1.2.0)\n",
            "Requirement already satisfied: audioread>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from librosa<0.10.0,>0.7.2->audiomentations) (3.0.0)\n",
            "Requirement already satisfied: decorator>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from librosa<0.10.0,>0.7.2->audiomentations) (4.4.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from librosa<0.10.0,>0.7.2->audiomentations) (21.3)\n",
            "Requirement already satisfied: scikit-learn!=0.19.0,>=0.14.0 in /usr/local/lib/python3.7/dist-packages (from librosa<0.10.0,>0.7.2->audiomentations) (1.0.2)\n",
            "Requirement already satisfied: resampy>=0.2.2 in /usr/local/lib/python3.7/dist-packages (from librosa<0.10.0,>0.7.2->audiomentations) (0.4.2)\n",
            "Requirement already satisfied: soundfile>=0.10.2 in /usr/local/lib/python3.7/dist-packages (from librosa<0.10.0,>0.7.2->audiomentations) (0.11.0)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from numba>=0.43.0->librosa<0.10.0,>0.7.2->audiomentations) (4.13.0)\n",
            "Requirement already satisfied: llvmlite<0.40,>=0.39.0dev0 in /usr/local/lib/python3.7/dist-packages (from numba>=0.43.0->librosa<0.10.0,>0.7.2->audiomentations) (0.39.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from numba>=0.43.0->librosa<0.10.0,>0.7.2->audiomentations) (57.4.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->librosa<0.10.0,>0.7.2->audiomentations) (3.0.9)\n",
            "Requirement already satisfied: appdirs>=1.3.0 in /usr/local/lib/python3.7/dist-packages (from pooch>=1.0->librosa<0.10.0,>0.7.2->audiomentations) (1.4.4)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.7/dist-packages (from pooch>=1.0->librosa<0.10.0,>0.7.2->audiomentations) (2.23.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->pooch>=1.0->librosa<0.10.0,>0.7.2->audiomentations) (2022.9.24)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->pooch>=1.0->librosa<0.10.0,>0.7.2->audiomentations) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->pooch>=1.0->librosa<0.10.0,>0.7.2->audiomentations) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->pooch>=1.0->librosa<0.10.0,>0.7.2->audiomentations) (3.0.4)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn!=0.19.0,>=0.14.0->librosa<0.10.0,>0.7.2->audiomentations) (3.1.0)\n",
            "Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.7/dist-packages (from soundfile>=0.10.2->librosa<0.10.0,>0.7.2->audiomentations) (1.15.1)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.7/dist-packages (from cffi>=1.0->soundfile>=0.10.2->librosa<0.10.0,>0.7.2->audiomentations) (2.21)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->numba>=0.43.0->librosa<0.10.0,>0.7.2->audiomentations) (3.10.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->numba>=0.43.0->librosa<0.10.0,>0.7.2->audiomentations) (4.1.1)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: pyroomacoustics in /usr/local/lib/python3.7/dist-packages (0.7.2)\n",
            "Requirement already satisfied: numpy>=1.13.0 in /usr/local/lib/python3.7/dist-packages (from pyroomacoustics) (1.21.6)\n",
            "Requirement already satisfied: pybind11>=2.2 in /usr/local/lib/python3.7/dist-packages (from pyroomacoustics) (2.10.1)\n",
            "Requirement already satisfied: scipy>=0.18.0 in /usr/local/lib/python3.7/dist-packages (from pyroomacoustics) (1.7.3)\n",
            "Requirement already satisfied: Cython in /usr/local/lib/python3.7/dist-packages (from pyroomacoustics) (0.29.32)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: pedalboard in /usr/local/lib/python3.7/dist-packages (0.6.4)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from pedalboard) (1.21.6)\n"
          ]
        }
      ],
      "source": [
        "#importing the libraries\n",
        "import os \n",
        "import cv2\n",
        "import numpy as np\n",
        "import matplotlib\n",
        "#This backend of matplotlib doesn't show plots to the user, but we can save them to Google Drive\n",
        "matplotlib.use('Agg')\n",
        "import matplotlib.pyplot as plt\n",
        "import pdb\n",
        "import librosa\n",
        "import librosa.display\n",
        "from scipy.io import wavfile\n",
        "import seaborn as sns\n",
        "from pathlib import Path\n",
        "import pylab\n",
        "import sys\n",
        "import soundfile as sf\n",
        "import tensorflow as tf\n",
        "!pip install audiomentations\n",
        "import torch\n",
        "import torchaudio\n",
        "from torchaudio import transforms\n",
        "import IPython.display as ipd\n",
        "# Define augmentation functions\n",
        "!pip install pyroomacoustics\n",
        "from audiomentations import AddGaussianNoise, PitchShift, TimeStretch, RoomSimulator\n",
        "from scipy import signal\n",
        "from scipy.signal import butter, lfilter, freqz, filtfilt\n",
        "!pip install pedalboard\n",
        "from pedalboard import Pedalboard, Reverb"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T3mhs-y6e5iD"
      },
      "source": [
        "# ➗ Define local functions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "35Y5pyDsbOJf"
      },
      "source": [
        "\n",
        "## Control functions \n",
        "In this section: the functions that define the outputPath and the analysis selection"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 368,
      "metadata": {
        "id": "sMVHTf6Wc0KF"
      },
      "outputs": [],
      "source": [
        "def outputPath(subfolder,filename,OUTPUT_DIR,destination):\n",
        "  file_path = os.path.join(subfolder, filename)\n",
        "  file_stem = Path(subfolder).stem\n",
        "  target_dir = f'class_{file_stem}'\n",
        "  destination_dir = os.path.join(os.path.join(OUTPUT_DIR, destination), target_dir)\n",
        "  # generate image name\n",
        "  file_stem = Path(file_path).stem\n",
        "  imageName = os.path.join(destination_dir, file_stem)\n",
        "  return file_path, destination_dir,imageName;"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o_5E3Y_H7UnT"
      },
      "source": [
        "## Plot Spectrogram and Mel-Spectrogram functions\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 369,
      "metadata": {
        "id": "YKLjUfw77O42"
      },
      "outputs": [],
      "source": [
        "def MelSpectrogramPlot(y,sample_rate,save_plot,imageName,overwriteControl,CMAP):\n",
        "  \n",
        "  M = librosa.feature.melspectrogram(y=y, sr=sample_rate, n_fft=1024) # non overlap = 512\n",
        "  M_db = librosa.power_to_db(M, ref=np.max)\n",
        "\n",
        "  outputName = f'{imageName}_regular.png'\n",
        "  if overwriteControl == 1 and os.path.exists(outputName):\n",
        "    return M_db\n",
        "\n",
        "  fig1 = plt.figure()\n",
        "\n",
        "  plt.figure(figsize=(20, 20), frameon=False)\n",
        "  librosa.display.specshow(M_db, sr=sample_rate, x_axis='time', \n",
        "                           y_axis='mel',cmap=CMAP)\n",
        "  #plt.colorbar()\n",
        "  plt.clim(-80,0)  # identical to caxis([-4,4]) in MATLAB\n",
        "  plt.ylim([0, 12000])\n",
        "  plt.axis('off')\n",
        "  \n",
        "  # save the plot\n",
        "  if save_plot == 1:\n",
        "    fig1 = plt.gcf()\n",
        "    pylab.savefig(outputName,bbox_inches='tight',pad_inches=0)\n",
        "    plt.cla()\n",
        "    pylab.close()\n",
        "    plt.close(fig1)\n",
        "  \n",
        "  return M_db"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J1vORkhunRTc"
      },
      "source": [
        "# 🏗 Data Normalization "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 370,
      "metadata": {
        "id": "tg_G9WQnPVwy"
      },
      "outputs": [],
      "source": [
        "# Data normalization function\n",
        "from audiomentations import Normalize, Compose\n",
        "# data normalization\n",
        "DataNormalization = Compose([Normalize(p=1.0)])  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v7dg0zDO27lD"
      },
      "source": [
        "# 🎨 Data augmentation Functions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k6XmeQSo5ZeT"
      },
      "source": [
        "## Data Augmentation to the Signal"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 371,
      "metadata": {
        "id": "ig2sKpfHnMLC"
      },
      "outputs": [],
      "source": [
        "def DataAugmentation(data,sample_rate,save_plot,imageName,overwriteControl,CMAP,result):\n",
        "  ## 1. Data Augmentation to the signal\n",
        "  Signal_Augmentation(data,sample_rate,save_plot,imageName,overwriteControl,CMAP)\n",
        "  \n",
        "  ## 2. Data Augmentation to the spectrogram\n",
        "  # Freq masking\n",
        "  paramf = 10 \n",
        "  FreqBandNum = 5\n",
        "  FrequencyMasking(result,paramf,FreqBandNum,sample_rate,\n",
        "                   save_plot,imageName,overwriteControl,CMAP)\n",
        "  # Time masking\n",
        "  paramt = 80\n",
        "  TimeBandNum = 30\n",
        "  TimeMasking(result,paramt,TimeBandNum,sample_rate,\n",
        "                  save_plot,imageName,overwriteControl,CMAP)\n",
        "  # Time + Frequency\n",
        "  param = 20\n",
        "  FreqBandNum = 3\n",
        "  TimeBandNum = 5\n",
        "  Freq_and_Time_Masking(result,param,TimeBandNum,FreqBandNum,sample_rate,\n",
        "                        save_plot,imageName,overwriteControl,CMAP)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 372,
      "metadata": {
        "id": "ASgQ2A_xocYG"
      },
      "outputs": [],
      "source": [
        "def my_GaussianNoiseAddition(data, sample_rate):\n",
        "  # Play audio in Jupiter Notebook / Google Colab\n",
        "  #ipd.Audio('audio/conga_groove.wav') # load a local WAV file\n",
        "  #ipd.Audio(data, rate=sample_rate) # load a NumPy array\n",
        "  rms = np.sqrt(np.mean(data**2))\n",
        "  # Noise is 5% of RMS value of the signal\n",
        "  noiseMean = 0.05*rms\n",
        "  noiseLen = len(data)\n",
        "  stdDevNoise = 0.05*np.std(data)\n",
        "  noise = np.random.normal(noiseMean,stdDevNoise,noiseLen)\n",
        "  # noiseMean is the mean of the normal distribution you are choosing from\n",
        "  # stdDevNoise is the standard deviation of the normal distribution\n",
        "  # noiseLen is the number of elements you get in array noise\n",
        "  noisyData = data+noise\n",
        "  #ipd.Audio(data2, rate=sample_rate) # load a NumPy array\n",
        "  return noisyData"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 373,
      "metadata": {
        "id": "Q7GZlEZ05iHd"
      },
      "outputs": [],
      "source": [
        "def Signal_Augmentation(data,sample_rate,save_plot,imageName,overwriteControl,CMAP):\n",
        "   \n",
        "  # shift pitch (shift a random number of semitones between min_semitones and max_semitones)\n",
        "  pitchShifting = Compose([PitchShift(min_semitones = -2, max_semitones = -2, p=1)])\n",
        "\n",
        "  # stretch time\n",
        "  timeStretch = Compose([TimeStretch(min_rate=0.8,max_rate=1.25,leave_length_unchanged=True,p=1.0)])\n",
        "\n",
        "  # Make a Pedalboard object, containing a reverb plugins:\n",
        "  board = Pedalboard([Reverb(room_size=0.25)])\n",
        "\n",
        "  # Save plot = 0 or the picture will overwrite the non-augmented one\n",
        "  # also overwritecontrol = 0, because it is not necessary in this case\n",
        "  outputName = f'{imageName}_GaussianNoise.png'\n",
        "  if not(overwriteControl == 1 and os.path.exists(outputName)): \n",
        "    # For noise addition I use my own function\n",
        "    noisy_signal = my_GaussianNoiseAddition(data,sample_rate)\n",
        "    MelSpectrogramPlot(noisy_signal,sample_rate,0,imageName, 0,CMAP)\n",
        "    if save_plot == 1:\n",
        "      fig = plt.gcf()\n",
        "      pylab.savefig(outputName,bbox_inches='tight',pad_inches=0)\n",
        "      pylab.close()\n",
        " \n",
        "  outputName = f'{imageName}_PitchShifted.png'\n",
        "  if not(overwriteControl == 1 and os.path.exists(outputName)): \n",
        "    # Pitch Shifting\n",
        "    pitchy_signal = pitchShifting(data,sample_rate)\n",
        "    MelSpectrogramPlot(pitchy_signal,sample_rate,0,imageName, 0,CMAP)\n",
        "    if save_plot == 1:\n",
        "      fig = plt.gcf()\n",
        "      pylab.savefig(outputName,bbox_inches='tight',pad_inches=0)\n",
        "      pylab.close()\n",
        "\n",
        "  outputName = f'{imageName}_Stretched.png'\n",
        "  if not(overwriteControl == 1 and os.path.exists(outputName)): \n",
        "    stretchy_signal = timeStretch(data,sample_rate)\n",
        "    MelSpectrogramPlot(stretchy_signal,sample_rate,0,imageName, 0,CMAP)\n",
        "    if save_plot == 1:\n",
        "      fig = plt.gcf()\n",
        "      pylab.savefig(outputName,bbox_inches='tight',pad_inches=0)\n",
        "      pylab.close()\n",
        "  \n",
        "  outputName = f'{imageName}_LargeRoom.png'\n",
        "  if not(overwriteControl == 1 and os.path.exists(outputName)): \n",
        "    # Add Reverb, see pedalboard by spotify\n",
        "    # Run the audio through this pedalboard!\n",
        "    roomSim_signal = board(data,sample_rate)\n",
        "    ipd.Audio(data, rate=sample_rate)\n",
        "    ipd.Audio(roomSim_signal, rate=sample_rate)\n",
        "    MelSpectrogramPlot(roomSim_signal,sample_rate,0,imageName, 0,CMAP)\n",
        "    if save_plot == 1:\n",
        "      fig = plt.gcf()\n",
        "      pylab.savefig(outputName,bbox_inches='tight',pad_inches=0)\n",
        "      pylab.close()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ypiYdp7t5emp"
      },
      "source": [
        "##Data Augmentation to the Spectrogram/Plot 🤿"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6cQjCuypBh1S"
      },
      "source": [
        "### Time Masking"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 374,
      "metadata": {
        "id": "437qu6Ourawz"
      },
      "outputs": [],
      "source": [
        "def my_time_mask(input, param, TimeNum, name=None):\n",
        "    \"\"\"\n",
        "    Apply masking to a spectrogram in the freq domain.\n",
        "    Args:\n",
        "      input: An audio spectogram.\n",
        "      param: Parameter of masking.\n",
        "      name: A name for the operation (optional).\n",
        "    Returns:\n",
        "      A tensor of spectrogram.\n",
        "    \"\"\"\n",
        "    input = tf.convert_to_tensor(input)\n",
        "    minElement = tf.reduce_min(input)\n",
        "    # TODO: Support audio with channel > 1.\n",
        "    time_max = tf.shape(input)[1]\n",
        "    # calculate the indexes for all the frequencies\n",
        "    indices = tf.reshape(tf.range(time_max), (1, -1))\n",
        "    for x in range(TimeNum):\n",
        "      # param is the max value of a uniform random distribution\n",
        "      t = tf.random.uniform(shape=(), minval=0, \n",
        "                            maxval=param, dtype=tf.dtypes.int32)\n",
        "      # t0 is a random selected number from a uniform distribution \n",
        "      # with range (0, time_max-t)\n",
        "      t0 = tf.random.uniform(shape=(), minval=0, \n",
        "                             maxval=time_max + t, dtype=tf.dtypes.int32)\n",
        "      # select all the frequencies greater or equal to t0\n",
        "      cond1 = tf.math.greater_equal(indices, t0)\n",
        "      # select all the frequencies smaller than t0 + t\n",
        "      cond2 = tf.math.less(indices, t0 + t)\n",
        "      # select all the frequencies between t0 and t0 + t\n",
        "      condition = tf.math.logical_and(cond1, cond2)\n",
        "      time_mask = tf.where(condition,  minElement, input)\n",
        "    return time_mask"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 375,
      "metadata": {
        "id": "sz5wh6Du5iU-"
      },
      "outputs": [],
      "source": [
        "def TimeMasking(result,param,TimeNum,sample_rate,save_plot,imageName,overwriteControl,CMAP):\n",
        "  \n",
        "  outputName = f'{imageName}_TimeMasked.png'\n",
        "  if overwriteControl == 1 and os.path.exists(outputName):\n",
        "    return \n",
        "  \n",
        "  # Freq masking\n",
        "  # Convert ndarray representing the spectrogram to a tensor for pytorch\n",
        "  result_tensor = torch.from_numpy(result)        \n",
        "  time_mask = my_time_mask(result_tensor, param, TimeNum)\n",
        "  plt.figure(figsize=(20, 20),frameon=False)\n",
        "\n",
        "  # TO DO: now the plot is limited to mel-spectrogram, define data augmentation also for MFCC, spectrogram, etc..\n",
        "  librosa.display.specshow(time_mask.numpy(), sr=sample_rate, x_axis='time', \n",
        "                           y_axis='mel',cmap=CMAP)   \n",
        "  #plt.colorbar()\n",
        "  plt.clim(-80,0)  # identical to caxis([-4,4]) in MATLAB\n",
        "  plt.ylim([0, 12000])\n",
        "  plt.axis('off')   \n",
        "  \n",
        "  if save_plot == 1:\n",
        "    fig2 = plt.gcf()\n",
        "    pylab.savefig(outputName,bbox_inches='tight',pad_inches=0)\n",
        "    pylab.close()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Uosvnc4eBliJ"
      },
      "source": [
        "### Frequency Masking"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 376,
      "metadata": {
        "id": "yFUHqRYBUHBr"
      },
      "outputs": [],
      "source": [
        "def my_freq_mask(input, param, FreqNum, name=None):\n",
        "    \"\"\"\n",
        "    Apply masking to a spectrogram in the time domain.\n",
        "    Args:\n",
        "      input: An audio spectogram.\n",
        "      param: Parameter of masking.\n",
        "      name: A name for the operation (optional).\n",
        "    Returns:\n",
        "      A tensor of spectrogram.\n",
        "    \"\"\"\n",
        "    # code is quite similar to my_freq_mask\n",
        "    input = tf.convert_to_tensor(input)\n",
        "    minElement = tf.reduce_min(input)\n",
        "    # TODO: Support audio with channel > 1.\n",
        "    freq_max = tf.shape(input)[0]\n",
        "    indices = tf.reshape(tf.range(freq_max), (-1, 1))\n",
        "    for x in range(FreqNum):\n",
        "      f = tf.random.uniform(shape=(), minval=0, \n",
        "                          maxval=param, dtype=tf.dtypes.int32)\n",
        "      f0 = tf.random.uniform(shape=(), minval=0,\n",
        "                          maxval=freq_max - f, dtype=tf.dtypes.int32)\n",
        "      cond1 = tf.math.greater_equal(indices, f0)\n",
        "      cond2 = tf.math.less(indices, f0 + f)\n",
        "      condition = tf.math.logical_and(cond1, cond2)\n",
        "      masking = tf.where(condition, minElement, input)\n",
        "      input = masking\n",
        "    return masking"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 377,
      "metadata": {
        "id": "SJGSJn_LVbeX"
      },
      "outputs": [],
      "source": [
        "def FrequencyMasking(result,param,FreqNum,sample_rate,save_plot,imageName,overwriteControl,CMAP):\n",
        "  \n",
        "  outputName = f'{imageName}_FreqMasked.png'\n",
        "  if overwriteControl == 1 and os.path.exists(outputName):\n",
        "    return \n",
        "  \n",
        "  # Time masking\n",
        "  # Convert ndarray representing the spectrogram to a tensor for pytorch\n",
        "  result_tensor = torch.from_numpy(result)        \n",
        "  freq_mask = my_freq_mask(result_tensor, param, FreqNum)\n",
        "  \n",
        "  plt.figure(figsize=(20, 20), frameon=False)\n",
        "  librosa.display.specshow(freq_mask.numpy(), sr=sample_rate, x_axis='time', \n",
        "                           y_axis='mel',cmap=CMAP)   \n",
        "  #plt.colorbar()\n",
        "  plt.clim(-80,0)  # identical to caxis([-4,4]) in MATLAB\n",
        "  plt.ylim([0, 12000])\n",
        "  plt.axis('off')   \n",
        "  \n",
        "  if save_plot == 1:\n",
        "    fig2 = plt.gcf()\n",
        "    pylab.savefig(outputName,bbox_inches='tight',pad_inches=0)\n",
        "    pylab.close()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dG4k5A_QXKwI"
      },
      "source": [
        "### Time + Frequency Masking "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 378,
      "metadata": {
        "id": "in5xX7R1W7xH"
      },
      "outputs": [],
      "source": [
        "def Freq_and_Time_Masking(result,param,TimeNum,FreqNum,sample_rate,save_plot,imageName,overwriteControl,CMAP):\n",
        "  \n",
        "  outputName = f'{imageName}_Time_and_Freq_Masked.png'\n",
        "  if overwriteControl == 1 and os.path.exists(outputName):\n",
        "    return \n",
        "  \n",
        "  # Time masking\n",
        "  # Convert ndarray representing the spectrogram to a tensor for pytorch\n",
        "  result_tensor = torch.from_numpy(result)        \n",
        "  time_mask = my_time_mask(result_tensor, param, TimeNum)\n",
        "  \n",
        "  # Freq masking\n",
        "  # Convert ndarray representing the spectrogram to a tensor for pytorch\n",
        "  freq_mask = my_freq_mask(time_mask, param, FreqNum)\n",
        "\n",
        "  plt.figure(figsize=(20, 20),frameon=False)\n",
        "  librosa.display.specshow(freq_mask.numpy(), sr=sample_rate, x_axis='time', \n",
        "                           y_axis='mel',cmap=CMAP)   \n",
        "  #plt.colorbar()\n",
        "  plt.clim(-80,0)  # identical to caxis([-4,4]) in MATLAB\n",
        "  plt.ylim([0, 12000])\n",
        "  plt.axis('off')   \n",
        "  \n",
        "  if save_plot == 1:\n",
        "    fig = plt.gcf()\n",
        "    pylab.savefig(outputName,bbox_inches='tight',pad_inches=0)\n",
        "    pylab.close()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "beB6kUWfI4lJ"
      },
      "source": [
        "# ⛹ Define Input and Output directory "
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "fileName = 'DatasetTesiFinale_vowelE_FineCut_Short_perColab'\n",
        "zipfile = fileName + '.zip'\n",
        "directory = '/content/drive/MyDrive/TesiMagistrale/'\n",
        "\n",
        "zipPath = os.path.join(directory,zipfile)\n",
        "OUTPUT_DIR = os.path.join(directory,'outputSpectrogram')\n",
        "\n",
        "if not os.path.exists(OUTPUT_DIR):\n",
        "   # Create a new directory because it does not exist\n",
        "   os.makedirs(OUTPUT_DIR)\n",
        "   print(\"The output folder has been created!\")\n",
        "\n",
        "# Location of Zip File\n",
        "drive_path = zipPath\n",
        "local_path = '/content'\n",
        "\n",
        "zipCopyPath = os.path.join(local_path,zipfile)\n",
        "if not os.path.exists(zipCopyPath):\n",
        "  # Copy the zip file and move it up one level (AKA out of the drive folder)\n",
        "  !cp '{drive_path}' .\n",
        "else:\n",
        "  print('Files already transferred from Drive')\n",
        "\n",
        "if not os.path.exists(fileName):\n",
        "  # Navigate to the copied file and unzip it quietly\n",
        "  os.chdir(local_path)\n",
        "  !unzip -q '{zipfile}'\n",
        "else:\n",
        "  print('Files already unzipped')\n",
        "# change directory to the new one\n",
        "INPUT_DIR = os.path.join(local_path,fileName)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xPWalx0gr6jI",
        "outputId": "5af2a241-2bbb-40b7-8763-92a0afe6e6a4"
      },
      "execution_count": 379,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files already transferred from Drive\n",
            "Files already unzipped\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GTAmtjX2xA-d"
      },
      "source": [
        "# 🔎 Plot Mel-Spectrogram\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 380,
      "metadata": {
        "id": "QX52a40gw8ZG"
      },
      "outputs": [],
      "source": [
        "destination = 'Mel-Spectrogram' \n",
        "save_plot = 1; # if 1, save plot on Google Drive\n",
        "overwriteControl = 0;\n",
        "CMAP = 'jet'\n",
        "#plasma, jet, Greys, Greys_r (reverse), ..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gd6auTUxPXiJ"
      },
      "source": [
        "# 🏋 Choose whether to augment the data or not"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 381,
      "metadata": {
        "id": "-kTCQXvqbIrl"
      },
      "outputs": [],
      "source": [
        "doAugmentation = True"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8aLp35x-bZHz"
      },
      "source": [
        "If doesn't exists, make output directory"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 382,
      "metadata": {
        "id": "fj6Miy66bC_a"
      },
      "outputs": [],
      "source": [
        "# if not os.path.exists(os.path.join(OUTPUT_DIR, destination)):\n",
        "#     os.makedirs(os.path.join(OUTPUT_DIR, destination))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NvK0wQoUJGIx"
      },
      "source": [
        "# ✔ Generate Plot! "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q88vv9ObJEVW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "937aa1e3-36a2-4526-ef2b-ae050b2b5e56"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Now reading PD_ON_TesiPDL_VowelE_0021_FineCut_Short.wav\n",
            "Now reading PD_ON_TesiPDL_VowelE_0024_FineCut_Short.wav\n",
            "Now reading PD_ON_TesiPDL_VowelE_0054_SAP_2_FineCut_Short.wav\n",
            "Now reading PD_ON_TesiPDL_VowelE_0026_FineCut_Short.wav\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:12: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
            "  if sys.path[0] == '':\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:11: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
            "  # This is added back by InteractiveShellApp.init_path()\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:16: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
            "  app.launch_new_instance()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Now reading PD_ON_TesiPDL_VowelE_0017_FineCut_Short.wav\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:10: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
            "  # Remove the CWD from sys.path while we load stuff.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Now reading PD_ON_TesiPDL_VowelE_0029_FineCut_Short.wav\n",
            "Now reading PD_ON_TesiPDL_VowelE_0042_FineCut_Short.wav\n",
            "Now reading PD_ON_TesiPDL_VowelE_0039_FineCut_Short.wav\n"
          ]
        }
      ],
      "source": [
        "valid_formats = [\".wav\"]\n",
        "for folders in os.listdir(INPUT_DIR):\n",
        "  # select a subfolder\n",
        "  subfolder = os.path.join(INPUT_DIR,folders)\n",
        "  # select all the records in the subfolder\n",
        "  for filename in os.listdir(subfolder):\n",
        "    file_format = os.path.splitext(filename)[1] \n",
        "    if file_format.lower() in valid_formats:\n",
        "      # sr = 44100 convert all the audio file to a sample frequency of 44100\n",
        "      # sr = None leave the fs untouched\n",
        "      data, sample_rate = librosa.load(os.path.join(subfolder,filename),sr=44100)\n",
        "      # define output path\n",
        "      file_path, destination_dir, imageName = outputPath(subfolder,filename,OUTPUT_DIR,destination)\n",
        "      #fs_array.append(sample_rate)\n",
        "      print('Now reading', filename)\n",
        "      \n",
        "      # create destination folder if it doesn't exist\n",
        "      if not os.path.exists(destination_dir):\n",
        "        os.mkdir(destination_dir)\n",
        "      \n",
        "      # Normalize data\n",
        "      data = DataNormalization(data,sample_rate)      \n",
        "\n",
        "      # PreEmphasis\n",
        "      #data = librosa.effects.preemphasis(data)\n",
        "\n",
        "      # Plot the signal, result is an ndarray containing the plot\n",
        "      result = MelSpectrogramPlot(data,sample_rate,save_plot,imageName, overwriteControl,CMAP)\n",
        "      \n",
        "      if doAugmentation == True:\n",
        "        DataAugmentation(data,sample_rate,save_plot,\n",
        "                     imageName,overwriteControl,CMAP,result)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}