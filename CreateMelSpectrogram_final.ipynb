{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/pietrodileo/Python_for_MD_thesis/blob/main/CreateMelSpectrogram_final.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4v0ytLlfkqPe"
      },
      "source": [
        "# üîä **Audio Signal Visualization** \n",
        "## Generate easily different plot from audio signals stored in Google Drive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KK7-L87_4MWI"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "75sL32jtmAjS"
      },
      "source": [
        "## Import libraries üìö"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LuPxg6GVwA9r"
      },
      "outputs": [],
      "source": [
        "#importing the libraries\n",
        "import os \n",
        "import cv2\n",
        "import numpy as np\n",
        "import matplotlib\n",
        "#This backend of matplotlib doesn't show plots to the user, but we can save them to Google Drive\n",
        "matplotlib.use('Agg')\n",
        "import matplotlib.pyplot as plt\n",
        "import pdb\n",
        "import librosa\n",
        "import librosa.display\n",
        "from scipy.io import wavfile\n",
        "import seaborn as sns\n",
        "from pathlib import Path\n",
        "import pylab\n",
        "import sys\n",
        "import soundfile as sf\n",
        "import tensorflow as tf\n",
        "!pip install audiomentations\n",
        "import torch\n",
        "import torchaudio\n",
        "from torchaudio import transforms\n",
        "import IPython.display as ipd\n",
        "# Define augmentation functions\n",
        "!pip install pyroomacoustics\n",
        "from audiomentations import AddGaussianNoise, PitchShift, TimeStretch, RoomSimulator\n",
        "from scipy import signal\n",
        "from scipy.signal import butter, lfilter, freqz, filtfilt\n",
        "!pip install pedalboard\n",
        "from pedalboard import Pedalboard, Reverb"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T3mhs-y6e5iD"
      },
      "source": [
        "# ‚ûó Define local functions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "35Y5pyDsbOJf"
      },
      "source": [
        "\n",
        "## Control functions \n",
        "In this section: the functions that define the outputPath and the analysis selection"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 386,
      "metadata": {
        "id": "sMVHTf6Wc0KF"
      },
      "outputs": [],
      "source": [
        "def outputPath(subfolder,filename,OUTPUT_DIR,destination):\n",
        "  file_path = os.path.join(subfolder, filename)\n",
        "  file_stem = Path(subfolder).stem\n",
        "  target_dir = f'class_{file_stem}'\n",
        "  destination_dir = os.path.join(os.path.join(OUTPUT_DIR, destination), target_dir)\n",
        "  # generate image name\n",
        "  file_stem = Path(file_path).stem\n",
        "  imageName = os.path.join(destination_dir, file_stem)\n",
        "  return file_path, destination_dir,imageName;"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o_5E3Y_H7UnT"
      },
      "source": [
        "## Plot Spectrogram and Mel-Spectrogram functions\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 387,
      "metadata": {
        "id": "YKLjUfw77O42"
      },
      "outputs": [],
      "source": [
        "def MelSpectrogramPlot(y,sample_rate,save_plot,imageName,overwriteControl,CMAP):\n",
        "  \n",
        "  M = librosa.feature.melspectrogram(y=y, sr=sample_rate, n_fft=2048) # non overlap = 512\n",
        "  M_db = librosa.power_to_db(M, ref=np.max)\n",
        "\n",
        "  outputName = f'{imageName}_regular.png'\n",
        "  if overwriteControl == 1 and os.path.exists(outputName):\n",
        "    return M_db\n",
        "\n",
        "  fig1 = plt.figure()\n",
        "\n",
        "  plt.figure(figsize=(20, 20), frameon=False)\n",
        "  librosa.display.specshow(M_db, sr=sample_rate, x_axis='time', \n",
        "                           y_axis='mel',cmap=CMAP)\n",
        "  #plt.colorbar()\n",
        "  plt.clim(-80,0)  # identical to caxis([-4,4]) in MATLAB\n",
        "  plt.ylim([0, 12000])\n",
        "  plt.axis('off')\n",
        "  \n",
        "  # save the plot\n",
        "  if save_plot == 1:\n",
        "    fig1 = plt.gcf()\n",
        "    pylab.savefig(outputName,bbox_inches='tight',pad_inches=0)\n",
        "    plt.cla()\n",
        "    pylab.close()\n",
        "    plt.close(fig1)\n",
        "  \n",
        "  return M_db"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J1vORkhunRTc"
      },
      "source": [
        "# üèó Data Normalization "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 388,
      "metadata": {
        "id": "tg_G9WQnPVwy"
      },
      "outputs": [],
      "source": [
        "# Data normalization function\n",
        "from audiomentations import Normalize, Compose\n",
        "# data normalization\n",
        "DataNormalization = Compose([Normalize(p=1.0)])  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v7dg0zDO27lD"
      },
      "source": [
        "# üé® Data augmentation Functions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k6XmeQSo5ZeT"
      },
      "source": [
        "## Data Augmentation to the Signal"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 389,
      "metadata": {
        "id": "ig2sKpfHnMLC"
      },
      "outputs": [],
      "source": [
        "def DataAugmentation(data,sample_rate,save_plot,imageName,overwriteControl,CMAP,result):\n",
        "  ## 1. Data Augmentation to the signal\n",
        "  Signal_Augmentation(data,sample_rate,save_plot,imageName,overwriteControl,CMAP)\n",
        "  \n",
        "  ## 2. Data Augmentation to the spectrogram\n",
        "  # Freq masking\n",
        "  paramf = 10 \n",
        "  FreqBandNum = 5\n",
        "  FrequencyMasking(result,paramf,FreqBandNum,sample_rate,\n",
        "                   save_plot,imageName,overwriteControl,CMAP)\n",
        "  # Time masking\n",
        "  paramt = 80\n",
        "  TimeBandNum = 30\n",
        "  TimeMasking(result,paramt,TimeBandNum,sample_rate,\n",
        "                  save_plot,imageName,overwriteControl,CMAP)\n",
        "  # Time + Frequency\n",
        "  param = 20\n",
        "  FreqBandNum = 3\n",
        "  TimeBandNum = 5\n",
        "  Freq_and_Time_Masking(result,param,TimeBandNum,FreqBandNum,sample_rate,\n",
        "                        save_plot,imageName,overwriteControl,CMAP)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 390,
      "metadata": {
        "id": "ASgQ2A_xocYG"
      },
      "outputs": [],
      "source": [
        "def my_GaussianNoiseAddition(data, sample_rate):\n",
        "  # Play audio in Jupiter Notebook / Google Colab\n",
        "  #ipd.Audio('audio/conga_groove.wav') # load a local WAV file\n",
        "  #ipd.Audio(data, rate=sample_rate) # load a NumPy array\n",
        "  rms = np.sqrt(np.mean(data**2))\n",
        "  # Noise is 5% of RMS value of the signal\n",
        "  noiseMean = 0.05*rms\n",
        "  noiseLen = len(data)\n",
        "  stdDevNoise = 0.05*np.std(data)\n",
        "  noise = np.random.normal(noiseMean,stdDevNoise,noiseLen)\n",
        "  # noiseMean is the mean of the normal distribution you are choosing from\n",
        "  # stdDevNoise is the standard deviation of the normal distribution\n",
        "  # noiseLen is the number of elements you get in array noise\n",
        "  noisyData = data+noise\n",
        "  #ipd.Audio(data2, rate=sample_rate) # load a NumPy array\n",
        "  return noisyData"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 391,
      "metadata": {
        "id": "Q7GZlEZ05iHd"
      },
      "outputs": [],
      "source": [
        "def Signal_Augmentation(data,sample_rate,save_plot,imageName,overwriteControl,CMAP):\n",
        "   \n",
        "  # shift pitch (shift a random number of semitones between min_semitones and max_semitones)\n",
        "  pitchShifting = Compose([PitchShift(min_semitones = -2, max_semitones = -2, p=1)])\n",
        "\n",
        "  # stretch time\n",
        "  timeStretch = Compose([TimeStretch(min_rate=0.8,max_rate=1.25,leave_length_unchanged=True,p=1.0)])\n",
        "\n",
        "  # Make a Pedalboard object, containing a reverb plugins:\n",
        "  board = Pedalboard([Reverb(room_size=0.25)])\n",
        "\n",
        "  # Save plot = 0 or the picture will overwrite the non-augmented one\n",
        "  # also overwritecontrol = 0, because it is not necessary in this case\n",
        "  outputName = f'{imageName}_GaussianNoise.png'\n",
        "  if not(overwriteControl == 1 and os.path.exists(outputName)): \n",
        "    # For noise addition I use my own function\n",
        "    noisy_signal = my_GaussianNoiseAddition(data,sample_rate)\n",
        "    MelSpectrogramPlot(noisy_signal,sample_rate,0,imageName, 0,CMAP)\n",
        "    if save_plot == 1:\n",
        "      fig = plt.gcf()\n",
        "      pylab.savefig(outputName,bbox_inches='tight',pad_inches=0)\n",
        "      pylab.close()\n",
        " \n",
        "  outputName = f'{imageName}_PitchShifted.png'\n",
        "  if not(overwriteControl == 1 and os.path.exists(outputName)): \n",
        "    # Pitch Shifting\n",
        "    pitchy_signal = pitchShifting(data,sample_rate)\n",
        "    MelSpectrogramPlot(pitchy_signal,sample_rate,0,imageName, 0,CMAP)\n",
        "    if save_plot == 1:\n",
        "      fig = plt.gcf()\n",
        "      pylab.savefig(outputName,bbox_inches='tight',pad_inches=0)\n",
        "      pylab.close()\n",
        "\n",
        "  outputName = f'{imageName}_Stretched.png'\n",
        "  if not(overwriteControl == 1 and os.path.exists(outputName)): \n",
        "    stretchy_signal = timeStretch(data,sample_rate)\n",
        "    MelSpectrogramPlot(stretchy_signal,sample_rate,0,imageName, 0,CMAP)\n",
        "    if save_plot == 1:\n",
        "      fig = plt.gcf()\n",
        "      pylab.savefig(outputName,bbox_inches='tight',pad_inches=0)\n",
        "      pylab.close()\n",
        "  \n",
        "  outputName = f'{imageName}_LargeRoom.png'\n",
        "  if not(overwriteControl == 1 and os.path.exists(outputName)): \n",
        "    # Add Reverb, see pedalboard by spotify\n",
        "    # Run the audio through this pedalboard!\n",
        "    roomSim_signal = board(data,sample_rate)\n",
        "    ipd.Audio(data, rate=sample_rate)\n",
        "    ipd.Audio(roomSim_signal, rate=sample_rate)\n",
        "    MelSpectrogramPlot(roomSim_signal,sample_rate,0,imageName, 0,CMAP)\n",
        "    if save_plot == 1:\n",
        "      fig = plt.gcf()\n",
        "      pylab.savefig(outputName,bbox_inches='tight',pad_inches=0)\n",
        "      pylab.close()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ypiYdp7t5emp"
      },
      "source": [
        "##Data Augmentation to the Spectrogram/Plot ü§ø"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6cQjCuypBh1S"
      },
      "source": [
        "### Time Masking"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 392,
      "metadata": {
        "id": "437qu6Ourawz"
      },
      "outputs": [],
      "source": [
        "def my_time_mask(input, param, TimeNum, name=None):\n",
        "    \"\"\"\n",
        "    Apply masking to a spectrogram in the freq domain.\n",
        "    Args:\n",
        "      input: An audio spectogram.\n",
        "      param: Parameter of masking.\n",
        "      name: A name for the operation (optional).\n",
        "    Returns:\n",
        "      A tensor of spectrogram.\n",
        "    \"\"\"\n",
        "    input = tf.convert_to_tensor(input)\n",
        "    minElement = tf.reduce_min(input)\n",
        "    # TODO: Support audio with channel > 1.\n",
        "    time_max = tf.shape(input)[1]\n",
        "    # calculate the indexes for all the frequencies\n",
        "    indices = tf.reshape(tf.range(time_max), (1, -1))\n",
        "    for x in range(TimeNum):\n",
        "      # param is the max value of a uniform random distribution\n",
        "      t = tf.random.uniform(shape=(), minval=0, \n",
        "                            maxval=param, dtype=tf.dtypes.int32)\n",
        "      # t0 is a random selected number from a uniform distribution \n",
        "      # with range (0, time_max-t)\n",
        "      t0 = tf.random.uniform(shape=(), minval=0, \n",
        "                             maxval=time_max + t, dtype=tf.dtypes.int32)\n",
        "      # select all the frequencies greater or equal to t0\n",
        "      cond1 = tf.math.greater_equal(indices, t0)\n",
        "      # select all the frequencies smaller than t0 + t\n",
        "      cond2 = tf.math.less(indices, t0 + t)\n",
        "      # select all the frequencies between t0 and t0 + t\n",
        "      condition = tf.math.logical_and(cond1, cond2)\n",
        "      time_mask = tf.where(condition,  minElement, input)\n",
        "    return time_mask"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 393,
      "metadata": {
        "id": "sz5wh6Du5iU-"
      },
      "outputs": [],
      "source": [
        "def TimeMasking(result,param,TimeNum,sample_rate,save_plot,imageName,overwriteControl,CMAP):\n",
        "  \n",
        "  outputName = f'{imageName}_TimeMasked.png'\n",
        "  if overwriteControl == 1 and os.path.exists(outputName):\n",
        "    return \n",
        "  \n",
        "  # Freq masking\n",
        "  # Convert ndarray representing the spectrogram to a tensor for pytorch\n",
        "  result_tensor = torch.from_numpy(result)        \n",
        "  time_mask = my_time_mask(result_tensor, param, TimeNum)\n",
        "  plt.figure(figsize=(20, 20),frameon=False)\n",
        "\n",
        "  # TO DO: now the plot is limited to mel-spectrogram, define data augmentation also for MFCC, spectrogram, etc..\n",
        "  librosa.display.specshow(time_mask.numpy(), sr=sample_rate, x_axis='time', \n",
        "                           y_axis='mel',cmap=CMAP)   \n",
        "  #plt.colorbar()\n",
        "  plt.clim(-80,0)  # identical to caxis([-4,4]) in MATLAB\n",
        "  plt.ylim([0, 12000])\n",
        "  plt.axis('off')   \n",
        "  \n",
        "  if save_plot == 1:\n",
        "    fig2 = plt.gcf()\n",
        "    pylab.savefig(outputName,bbox_inches='tight',pad_inches=0)\n",
        "    pylab.close()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Uosvnc4eBliJ"
      },
      "source": [
        "### Frequency Masking"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 394,
      "metadata": {
        "id": "yFUHqRYBUHBr"
      },
      "outputs": [],
      "source": [
        "def my_freq_mask(input, param, FreqNum, name=None):\n",
        "    \"\"\"\n",
        "    Apply masking to a spectrogram in the time domain.\n",
        "    Args:\n",
        "      input: An audio spectogram.\n",
        "      param: Parameter of masking.\n",
        "      name: A name for the operation (optional).\n",
        "    Returns:\n",
        "      A tensor of spectrogram.\n",
        "    \"\"\"\n",
        "    # code is quite similar to my_freq_mask\n",
        "    input = tf.convert_to_tensor(input)\n",
        "    minElement = tf.reduce_min(input)\n",
        "    # TODO: Support audio with channel > 1.\n",
        "    freq_max = tf.shape(input)[0]\n",
        "    indices = tf.reshape(tf.range(freq_max), (-1, 1))\n",
        "    for x in range(FreqNum):\n",
        "      f = tf.random.uniform(shape=(), minval=0, \n",
        "                          maxval=param, dtype=tf.dtypes.int32)\n",
        "      f0 = tf.random.uniform(shape=(), minval=0,\n",
        "                          maxval=freq_max - f, dtype=tf.dtypes.int32)\n",
        "      cond1 = tf.math.greater_equal(indices, f0)\n",
        "      cond2 = tf.math.less(indices, f0 + f)\n",
        "      condition = tf.math.logical_and(cond1, cond2)\n",
        "      masking = tf.where(condition, minElement, input)\n",
        "      input = masking\n",
        "    return masking"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 395,
      "metadata": {
        "id": "SJGSJn_LVbeX"
      },
      "outputs": [],
      "source": [
        "def FrequencyMasking(result,param,FreqNum,sample_rate,save_plot,imageName,overwriteControl,CMAP):\n",
        "  \n",
        "  outputName = f'{imageName}_FreqMasked.png'\n",
        "  if overwriteControl == 1 and os.path.exists(outputName):\n",
        "    return \n",
        "  \n",
        "  # Time masking\n",
        "  # Convert ndarray representing the spectrogram to a tensor for pytorch\n",
        "  result_tensor = torch.from_numpy(result)        \n",
        "  freq_mask = my_freq_mask(result_tensor, param, FreqNum)\n",
        "  \n",
        "  plt.figure(figsize=(20, 20), frameon=False)\n",
        "  librosa.display.specshow(freq_mask.numpy(), sr=sample_rate, x_axis='time', \n",
        "                           y_axis='mel',cmap=CMAP)   \n",
        "  #plt.colorbar()\n",
        "  plt.clim(-80,0)  # identical to caxis([-4,4]) in MATLAB\n",
        "  plt.ylim([0, 12000])\n",
        "  plt.axis('off')   \n",
        "  \n",
        "  if save_plot == 1:\n",
        "    fig2 = plt.gcf()\n",
        "    pylab.savefig(outputName,bbox_inches='tight',pad_inches=0)\n",
        "    pylab.close()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dG4k5A_QXKwI"
      },
      "source": [
        "### Time + Frequency Masking "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 396,
      "metadata": {
        "id": "in5xX7R1W7xH"
      },
      "outputs": [],
      "source": [
        "def Freq_and_Time_Masking(result,param,TimeNum,FreqNum,sample_rate,save_plot,imageName,overwriteControl,CMAP):\n",
        "  \n",
        "  outputName = f'{imageName}_Time_and_Freq_Masked.png'\n",
        "  if overwriteControl == 1 and os.path.exists(outputName):\n",
        "    return \n",
        "  \n",
        "  # Time masking\n",
        "  # Convert ndarray representing the spectrogram to a tensor for pytorch\n",
        "  result_tensor = torch.from_numpy(result)        \n",
        "  time_mask = my_time_mask(result_tensor, param, TimeNum)\n",
        "  \n",
        "  # Freq masking\n",
        "  # Convert ndarray representing the spectrogram to a tensor for pytorch\n",
        "  freq_mask = my_freq_mask(time_mask, param, FreqNum)\n",
        "\n",
        "  plt.figure(figsize=(20, 20),frameon=False)\n",
        "  librosa.display.specshow(freq_mask.numpy(), sr=sample_rate, x_axis='time', \n",
        "                           y_axis='mel',cmap=CMAP)   \n",
        "  #plt.colorbar()\n",
        "  plt.clim(-80,0)  # identical to caxis([-4,4]) in MATLAB\n",
        "  plt.ylim([0, 12000])\n",
        "  plt.axis('off')   \n",
        "  \n",
        "  if save_plot == 1:\n",
        "    fig = plt.gcf()\n",
        "    pylab.savefig(outputName,bbox_inches='tight',pad_inches=0)\n",
        "    pylab.close()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "beB6kUWfI4lJ"
      },
      "source": [
        "# ‚õπ Define Input and Output directory "
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "fileName = 'DatasetTesiFinale_vowelE_FineCut_Short_perColab'\n",
        "zipfile = fileName + '.zip'\n",
        "directory = '/content/drive/MyDrive/TesiMagistrale/'\n",
        "\n",
        "zipPath = os.path.join(directory,zipfile)\n",
        "OUTPUT_DIR = os.path.join(directory,'outputSpectrogram')\n",
        "\n",
        "if not os.path.exists(OUTPUT_DIR):\n",
        "   # Create a new directory because it does not exist\n",
        "   os.makedirs(OUTPUT_DIR)\n",
        "   print(\"The output folder has been created!\")\n",
        "\n",
        "# Location of Zip File\n",
        "drive_path = zipPath\n",
        "local_path = '/content'\n",
        "\n",
        "zipCopyPath = os.path.join(local_path,zipfile)\n",
        "if not os.path.exists(zipCopyPath):\n",
        "  # Copy the zip file and move it up one level (AKA out of the drive folder)\n",
        "  !cp '{drive_path}' .\n",
        "else:\n",
        "  print('Files already transferred from Drive')\n",
        "\n",
        "if not os.path.exists(fileName):\n",
        "  # Navigate to the copied file and unzip it quietly\n",
        "  os.chdir(local_path)\n",
        "  !unzip -q '{zipfile}'\n",
        "else:\n",
        "  print('Files already unzipped')\n",
        "# change directory to the new one\n",
        "INPUT_DIR = os.path.join(local_path,fileName)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xPWalx0gr6jI",
        "outputId": "d9a640a3-43f9-4cd8-ce80-194fab4624a3"
      },
      "execution_count": 397,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files already transferred from Drive\n",
            "Files already unzipped\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GTAmtjX2xA-d"
      },
      "source": [
        "# üîé Plot Mel-Spectrogram\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 398,
      "metadata": {
        "id": "QX52a40gw8ZG"
      },
      "outputs": [],
      "source": [
        "destination = 'Mel-Spectrogram' \n",
        "save_plot = 1; # if 1, save plot on Google Drive\n",
        "overwriteControl = 1;\n",
        "CMAP = 'jet'\n",
        "#plasma, jet, Greys, Greys_r (reverse), ..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gd6auTUxPXiJ"
      },
      "source": [
        "# üèã Choose whether to augment the data or not"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 399,
      "metadata": {
        "id": "-kTCQXvqbIrl"
      },
      "outputs": [],
      "source": [
        "doAugmentation = True"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8aLp35x-bZHz"
      },
      "source": [
        "If doesn't exists, make output directory"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 400,
      "metadata": {
        "id": "fj6Miy66bC_a"
      },
      "outputs": [],
      "source": [
        "# if not os.path.exists(os.path.join(OUTPUT_DIR, destination)):\n",
        "#     os.makedirs(os.path.join(OUTPUT_DIR, destination))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NvK0wQoUJGIx"
      },
      "source": [
        "# ‚úî Generate Plot! "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q88vv9ObJEVW"
      },
      "outputs": [],
      "source": [
        "valid_formats = [\".wav\"]\n",
        "for folders in os.listdir(INPUT_DIR):\n",
        "  # select a subfolder\n",
        "  subfolder = os.path.join(INPUT_DIR,folders)\n",
        "  # select all the records in the subfolder\n",
        "  for filename in os.listdir(subfolder):\n",
        "    file_format = os.path.splitext(filename)[1] \n",
        "    if file_format.lower() in valid_formats:\n",
        "      # sr = 44100 convert all the audio file to a sample frequency of 44100\n",
        "      # sr = None leave the fs untouched\n",
        "      data, sample_rate = librosa.load(os.path.join(subfolder,filename),sr=44100)\n",
        "      # define output path\n",
        "      file_path, destination_dir, imageName = outputPath(subfolder,filename,OUTPUT_DIR,destination)\n",
        "      #fs_array.append(sample_rate)\n",
        "      print('Now reading', filename)\n",
        "      \n",
        "      # create destination folder if it doesn't exist\n",
        "      if not os.path.exists(destination_dir):\n",
        "        os.mkdir(destination_dir)\n",
        "      \n",
        "      # Normalize data\n",
        "      data = DataNormalization(data,sample_rate)      \n",
        "\n",
        "      # PreEmphasis\n",
        "      #data = librosa.effects.preemphasis(data)\n",
        "\n",
        "      # Plot the signal, result is an ndarray containing the plot\n",
        "      result = MelSpectrogramPlot(data,sample_rate,save_plot,imageName, overwriteControl,CMAP)\n",
        "      \n",
        "      if doAugmentation == True:\n",
        "        DataAugmentation(data,sample_rate,save_plot,\n",
        "                     imageName,overwriteControl,CMAP,result)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}