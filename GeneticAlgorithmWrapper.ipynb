{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPgXKyckY83MNj+X04tQI6+",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/pietrodileo/Python_for_MD_thesis/blob/main/GeneticAlgorithmWrapper.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Genetic Algorithm"
      ],
      "metadata": {
        "id": "lITfwkn76byn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_selection import mutual_info_classif\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy.stats import pointbiserialr\n",
        "from math import sqrt\n",
        "from sklearn.feature_selection import SelectKBest\n",
        "import random\n",
        "import time\n",
        "import random\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import copy\n",
        "import math\n",
        "import tensorflow\n",
        "import sklearn\n",
        "import keras\n",
        "\n",
        "from keras.optimizers import Adam\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, LSTM\n",
        "\n",
        "from sklearn.metrics import accuracy_score\n",
        "%matplotlib inline"
      ],
      "metadata": {
        "id": "iog1O-Lr6g0H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Here's a function for DataFrames (again from SO):\n",
        "\n",
        "from collections import defaultdict\n",
        "\n",
        "def reverse_dummy(df_dummies):\n",
        "    pos = defaultdict(list)\n",
        "    vals = defaultdict(list)\n",
        "\n",
        "    for i, c in enumerate(df_dummies.columns):\n",
        "        if \"_\" in c:\n",
        "            k, v = c.split(\"_\", 1)\n",
        "            pos[k].append(i)\n",
        "            vals[k].append(v)\n",
        "        else:\n",
        "            pos[\"_\"].append(i)\n",
        "\n",
        "    df = pd.DataFrame({k: pd.Categorical.from_codes(\n",
        "                              np.argmax(df_dummies.iloc[:, pos[k]].values, axis=1),\n",
        "                              vals[k])\n",
        "                      for k in vals})\n",
        "\n",
        "    df[df_dummies.columns[pos[\"_\"]]] = df_dummies.iloc[:, pos[\"_\"]]\n",
        "    return df"
      ],
      "metadata": {
        "id": "nMYmrLAmHjMK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras import backend as K\n",
        "\n",
        "def recall_fun(y_true, y_pred):\n",
        "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
        "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
        "    recall = true_positives / (possible_positives + K.epsilon())\n",
        "    return recall\n",
        "\n",
        "def precision_fun(y_true, y_pred):\n",
        "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
        "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
        "    precision = true_positives / (predicted_positives + K.epsilon())\n",
        "    return precision\n",
        "\n",
        "def f1_fun(y_true, y_pred):\n",
        "    precision = precision_fun(y_true, y_pred)\n",
        "    recall = recall_fun(y_true, y_pred)\n",
        "    return 2*((precision*recall)/(precision+recall+K.epsilon()))"
      ],
      "metadata": {
        "id": "E45bStq88-YQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_dataframes_for_training(dataframe, split_frac=0.8):\n",
        "    \"\"\"\n",
        "    Generates training and testing dataframes from a complete dataframe, according to the split_frac parameter\n",
        "    \"\"\"\n",
        "    train_data = dataframe.sample(frac=split_frac, random_state=314)\n",
        "    test_data = dataframe.drop(train_data.index)\n",
        "    \n",
        "    X_train = train_data.loc[:, train_data.columns != 'Class']\n",
        "    X_test = test_data.loc[:, test_data.columns != 'Class']\n",
        "    y_train = train_data.loc[:, train_data.columns == 'Class']\n",
        "    y_test = test_data.loc[:, test_data.columns == 'Class']\n",
        "\n",
        "    print(X_train.shape)\n",
        "    print(X_test.shape)\n",
        "    print(y_train.shape)\n",
        "    print(y_test.shape)\n",
        "    \n",
        "    return X_train, X_test, y_train, y_test"
      ],
      "metadata": {
        "id": "nK6iluRA8Qkx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# GETTER FOR UNIQUE VALUES\n",
        "def get_uniques(dataframe):\n",
        "    for feature in dataframe.columns:\n",
        "\n",
        "        print(f\"Feature {feature}: \\n{list(pd.Series(dataframe[feature]).unique())}\")"
      ],
      "metadata": {
        "id": "Bi767K546dZb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# GETTER FOR UNIQUE VALUES\n",
        "def get_uniques(dataframe):\n",
        "    for feature in dataframe.columns:\n",
        "\n",
        "        print(f\"Feature {feature}: \\n{list(pd.Series(dataframe[feature]).unique())}\")"
      ],
      "metadata": {
        "id": "LUL2CfYi6le_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Functions for Genetic Algorithms"
      ],
      "metadata": {
        "id": "hp8BaLVK7O07"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def create_model(X, verbose=False):\n",
        "    \"\"\"\n",
        "    X: training dataset to be used. Its shape is used to set the input shape for the model.\n",
        "    \"\"\"\n",
        "    \n",
        "    model = Sequential()\n",
        "    \n",
        "    model.add(Dense(32, input_dim=X.shape[1], activation='relu'))\n",
        "    model.add(Dense(64, activation='relu'))\n",
        "    model.add(Dense(1, activation='sigmoid'))\n",
        "    \n",
        "    if verbose: print('MODEL SUMMARY: \\n')\n",
        "    if verbose: print(model.summary())\n",
        "    \n",
        "    model.compile(loss='binary_crossentropy', optimizer='rmsprop', metrics=['accuracy'])\n",
        "    \n",
        "    return model"
      ],
      "metadata": {
        "id": "5Lmi5Jo06x9E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_n_individual(counter, population):\n",
        "    \"\"\"\n",
        "    If counter is 0, return the individual with the highest prob\n",
        "    If counter is 1, return the second individual with the highest prob\n",
        "    If counter is 2, return the third individual withthe highest prob\n",
        "    \"\"\"\n",
        "    index = counter + 1\n",
        "    probabilities = [ind[1] for ind in population]\n",
        "    sorted_probs = sorted(probabilities, key=float)\n",
        "    max_prob = probabilities[-index]\n",
        "    max_individual = [ind[0] for ind in population if ind[1] == max_prob][0]\n",
        "    \n",
        "    return max_individual\n",
        "\n"
      ],
      "metadata": {
        "id": "z8fTELFmC5ym"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "First, randomly define N possible solutions to the problem"
      ],
      "metadata": {
        "id": "gcTOj1CNDBTZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_random_individuals(num_individuals, num_features, max_features=None, verbose=False):\n",
        "    \"\"\"\n",
        "    Randomly generates individuals\n",
        "\n",
        "    The number of individuals to generate is given by the num_individuals parameter\n",
        "    The length of each individual is equal to the num_features parameter\n",
        "    The maximum number of active features for every individual is given by the max_features parameter\n",
        "    \"\"\"\n",
        "    if verbose: print('GENERATING RANDOM INDIVIDUALS.... ')\n",
        "        \n",
        "    individuals = list()\n",
        "    \n",
        "    for _ in range(num_individuals):\n",
        "        individual = ''\n",
        "        for col in range(num_features):\n",
        "            # For each char in the individual, a 1 or a 0 is randomly generated\n",
        "            if individual.count('1') == max_features:\n",
        "                individual += '0'\n",
        "                continue\n",
        "                \n",
        "            individual += str(random.randint(0, 1))\n",
        "            \n",
        "        if verbose: print(f'Generated a new individual: {individual}')\n",
        "        individuals.append(individual)\n",
        "        \n",
        "    if verbose: print(f'Generated list of {num_individuals} individuals: {individuals}')\n",
        "        \n",
        "    return individuals"
      ],
      "metadata": {
        "id": "urtwgBY8C-wz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Fitness Evaluation of the current individual (= set of features)\n",
        "\n",
        "Fitness is based on a neural network"
      ],
      "metadata": {
        "id": "B5udGQfeEMkH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_fitness_func(individual, dataframe, verbose=False):\n",
        "    \"\"\"\n",
        "    Calculate accuracy for the individual passed as parameter.\n",
        "    Both the dataframe and the y_data parameters are used for training and evaluating the model.\n",
        "    \"\"\"\n",
        "    if verbose: print('Calculating accuracy for individual ', individual)\n",
        "    \n",
        "    # generate_dataframes_for_training() function splits a given dataset into training and test data, \n",
        "    # and separates labels and rest of features\n",
        "    X_train, X_test, y_train, y_test = generate_dataframes_for_training(dataframe)\n",
        "    \n",
        "    X_train = X_train.loc[:, [True if individual[i] == '1' else False for i in range(len(individual))]]\n",
        "    X_test = X_test.loc[:, [True if individual[i] == '1' else False for i in range(len(individual))]]    \n",
        "    \n",
        "    model = create_model(X_train, individual)\n",
        "\n",
        "    X_train = np.asarray(X_train).astype(np.float64)\n",
        "    X_test = np.asarray(X_test).astype(np.float64)\n",
        "    y_train = np.asarray(y_train).astype(np.float64)\n",
        "    y_test = np.asarray(y_test).astype(np.float64)\n",
        "\n",
        "    model.fit(X_train, y_train, epochs=100, verbose=0)\n",
        "    \n",
        "    pred = model.predict(X_test)\n",
        "    accuracy = accuracy_score(y_test, pred.round())\n",
        "    if verbose: print(f\"Accuracy for the classifier trained for individual {individual}: \\n\", accuracy,'\\n')\n",
        "    \n",
        "    return accuracy\n"
      ],
      "metadata": {
        "id": "vkNWuNI9EK7c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Get Weights of the current population (needed in reproduction step)"
      ],
      "metadata": {
        "id": "z7oh-YtNHdEB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# This function perform Roulette Wheel Selection\n",
        "def get_weights_wheel(population):\n",
        "    \"\"\"\n",
        "    Calculate weights from the population filled with the accuracies\n",
        "    \"\"\"\n",
        "    total_accuracies = 0\n",
        "    new_population = []\n",
        "    \n",
        "    # Get the sum of all accuracies of the population\n",
        "    for individual in population:\n",
        "        total_accuracies += individual[1]\n",
        "        \n",
        "    # For each individual, calculate its weight by dividing its accuracy by the overall sum calculated above\n",
        "    for individual in population:\n",
        "        weight = individual[1]/total_accuracies\n",
        "        # Store the individual and its weight in the final population list\n",
        "        new_population.append((individual[0], float(weight*100)))\n",
        "        \n",
        "    return new_population\n",
        "\n",
        "# This function perform Rank Selection\n",
        "def get_weights_rank(population):\n",
        "    \"\"\"\n",
        "    Calculate weights from the population filled with the accuracies\n",
        "    \"\"\"\n",
        "    new_population = []\n",
        "    N = len(population[0])\n",
        "    # Use the gauss formula to get the sum of all ranks (sum of integers 1 to N).\n",
        "    TotalFitness = (N + 1) * N / 2;\n",
        "\n",
        "    # For each individual, calculate its weight by dividing its accuracy by the overall sum calculated above\n",
        "    for individual in population:\n",
        "        weight = individual/TotalFitness\n",
        "        # Store the individual and its weight in the final population list\n",
        "        new_population.append((individual[0], float(weight*100)))\n",
        "        \n",
        "    return new_population"
      ],
      "metadata": {
        "id": "ZSKzLBI-HaT2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Evaluate all the individuals one by one"
      ],
      "metadata": {
        "id": "faqPZHm8GObQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def fill_population(individuals, dataframe, verbose=False):\n",
        "    \"\"\"\n",
        "    Fills the population list with individuals and their weights\n",
        "    \"\"\"\n",
        "    population = list()\n",
        "    \n",
        "    for individual in individuals:\n",
        "        \n",
        "        # Get the value of the fitness function (accuracy of the model)\n",
        "        if verbose: \n",
        "          print(f'\\n Calculating fitness function value for individual {individual} \\n')\n",
        "        \n",
        "        # Evaluate current individual\n",
        "        accuracy = get_fitness_func(individual, dataframe, verbose)\n",
        "        \n",
        "        # Check that the value is not the goal state (in this case, an accuracy of 80% is a terminal state)\n",
        "        if float(accuracy) > 0.8:\n",
        "            if verbose: print(f'Goal state found for individual {individual}')\n",
        "            return individual\n",
        "            \n",
        "        individual_complete = (individual, accuracy)\n",
        "        population.append(individual_complete)\n",
        "        \n",
        "    # The final population list is created, which contains each individual together with its weight\n",
        "    # (weights will be used in the reproduction step)\n",
        "    new_population = get_weights_rank(population)\n",
        "    # Alternative: roulette wheel selection\n",
        "    #new_population = get_weights_wheel(population)\n",
        "    if verbose: print(f'Generated population list (with weights): {new_population}')\n",
        "    \n",
        "    return new_population"
      ],
      "metadata": {
        "id": "aZ7yahKdFKyS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Choose parents and reproduce them"
      ],
      "metadata": {
        "id": "3nBpu7J8Nvhl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def choose_parents(population, counter):\n",
        "    \"\"\"\n",
        "    From the population, weighting the probabilities of an individual being chosen via the fitness\n",
        "    function, takes randomly two individual to reproduce\n",
        "    Population is a list of tuples, where the first element is the individual and the second\n",
        "    one is the probability associated to it.\n",
        "    To avoid generating repeated individuals, 'counter' parameter is used to pick parents in different ways, thus\n",
        "    generating different individuals\n",
        "    \"\"\"\n",
        "    # Pick random parent Number 1 and Number 2\n",
        "    # (get_n_individual() function randomly picks an individual following the distribution of the weights)\n",
        "    if counter == 0:        \n",
        "        parent_1 = get_n_individual(0, population)        \n",
        "        parent_2 = get_n_individual(1, population)\n",
        "    elif counter == 1:\n",
        "        parent_1 = get_n_individual(0, population)        \n",
        "        parent_2 = get_n_individual(2, population)\n",
        "        \n",
        "    else:\n",
        "        probabilities = (individual[1] for individual in population)\n",
        "        individuals = [individual[0] for individual in population]\n",
        "        parent_1, parent_2 = random.choices(individuals, weights=probabilities, k=2)\n",
        "    \n",
        "    return [parent_1, parent_2]\n",
        "\n",
        "def mutate(child, prob=0.1):\n",
        "    \"\"\"\n",
        "    Randomly mutates an individual according to the probability given by prob parameter\n",
        "    \"\"\"\n",
        "    new_child = copy.deepcopy(child)\n",
        "    for i, char in enumerate(new_child):\n",
        "        if random.random() < prob:\n",
        "            new_value = '1' if char == '0' else '0'\n",
        "            new_child = new_child[:i] + new_value + new_child[i+1:]\n",
        "    \n",
        "    return new_child\n",
        "\n",
        "def reproduce(individual_1, individual_2):\n",
        "    \"\"\"\n",
        "    Takes 2 individuals, and combines their information based on a\n",
        "    randomly chosen crosspoint.\n",
        "    Each reproduction returns 2 new individuals\n",
        "    \"\"\" \n",
        "    # Randomly generate a integer between 1 and the length of the individuals minus one, which will be the crosspoint\n",
        "    crosspoint = random.randint(1, len(individual_1)-1)\n",
        "    child_1 = individual_1[:crosspoint] + individual_2[crosspoint:]\n",
        "    child_2 = individual_2[:crosspoint] + individual_1[crosspoint:]\n",
        "    child_1, child_2 = mutate(child_1), mutate(child_2)\n",
        " \n",
        "    return [child_1, child_2]\n",
        "\n",
        "def generation_ahead(population, verbose=False):\n",
        "    \"\"\"\n",
        "    Reproduces all the steps for choosing parents and making \n",
        "    childs, which means creating a new generation to iterate with\n",
        "    \"\"\"\n",
        "    new_population = list()\n",
        "    \n",
        "    for _ in range(int(len(population)//2)):      \n",
        "        # According to the weights calculated before, choose a set of parents to reproduce\n",
        "        parents = choose_parents(population, counter=_)\n",
        "        if verbose: print(f'Parents chosen: {parents}')\n",
        "          \n",
        "        # Reproduce the pair of individuals chose above to generate two new individuals\n",
        "        childs = reproduce(parents[0], parents[1])\n",
        "        if verbose: print(f'Generated children: {childs}\\n')\n",
        "        new_population += childs\n",
        "        \n",
        "    return new_population"
      ],
      "metadata": {
        "id": "BzWbNKwbFaWw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Main Loop"
      ],
      "metadata": {
        "id": "iKlM-CmUEjii"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def main_loop(ind_num, dataframe, max_iter=5, verbose=False):\n",
        "    \"\"\"\n",
        "    Performs all the steps of the Genetic Algorithm\n",
        "    1. Generate random population\n",
        "    2. Fill population with the weights of each individual\n",
        "    3. Check if the goal state is reached\n",
        "    4. Reproduce the population, and create a new generation\n",
        "    5. Repeat process until termination condition is met\n",
        "    \"\"\"\n",
        "    num_features = len(dataframe.columns)-1\n",
        "    # Generate individuals (returns a list of strings, where each str represents an individual)\n",
        "    individuals = generate_random_individuals(ind_num, num_features, random.randint(0, num_features), verbose)\n",
        "    \n",
        "    # Returns a list of tuples, where each tuple represents an individual and its weight\n",
        "    population = fill_population(individuals, dataframe, verbose)\n",
        "    \n",
        "    # Check if a goal state is reached\n",
        "    # When goal state is reached, fill_population() function returns a str, otherwise continue\n",
        "    if isinstance(population, str):\n",
        "        # Evaluate current population\n",
        "        accuracy = get_fitness_func(population, dataframe, verbose)\n",
        "        return population, accuracy\n",
        "        \n",
        "    # Reproduce current generation to generate a better new one\n",
        "    new_generation = generation_ahead(population, verbose)\n",
        "    \n",
        "    # After the new generation is generated, the loop goes on until a solution is found or until the maximum number of\n",
        "    # iterations are reached\n",
        "    iteration_count = 0\n",
        "    while iteration_count < max_iter:\n",
        "        if verbose: print(f'\\n\\n\\nITERATION NUMBER {iteration_count+1} (Iteration max = {max_iter+1})\\n\\n\\n')\n",
        "        population = fill_population(new_generation, dataframe, verbose)\n",
        "        \n",
        "        # Check if a goal state is reached\n",
        "        if isinstance(population, str):\n",
        "            break\n",
        "        \n",
        "        new_generation = generation_ahead(population, verbose)   \n",
        "        iteration_count += 1\n",
        "        \n",
        "    return population\n"
      ],
      "metadata": {
        "id": "cBLu_M2YEiCs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Feature Selection"
      ],
      "metadata": {
        "id": "seTVOd057UX3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# load the dataset\n",
        "task = 'C14'\n",
        "excelName = '/content/drive/MyDrive/TesiMagistrale/ExcelForTraining'+'/'+task+'.xlsx'\n",
        "df = pd.read_excel(excelName)\n",
        "outpath = '/content/drive/MyDrive/TesiMagistrale/ExcelForTraining/RisultatiFeatureSelection'\n",
        "# Replace NaN with zero on all columns \n",
        "df = df.fillna(0)\n",
        "\n",
        "# name of the label (can be seen in the dataframe)\n",
        "label = 'Class'\n",
        "istance = 'Istance'\n",
        "\n",
        "# list with feature names (V1, V2, V3, ...)\n",
        "features = df.columns.tolist()\n",
        "# keep only numerical values\n",
        "features.remove(label)\n",
        "features.remove(istance)\n",
        "\n",
        "# make a label dataframe\n",
        "labelVec = df.Class\n",
        "# create dummy variables\n",
        "labelDummy = pd.get_dummies(labelVec)\n",
        "labelDummy.columns = list(range(0, len(labelDummy.columns)))\n",
        "\n",
        "# reverseDummy: change class labeling to 0 and 1\n",
        "ClassNumerical = pd.DataFrame(labelDummy.idxmax(axis=1))\n",
        "ClassNumerical.columns = ['Class']\n",
        "# convert dataframe to series\n",
        "ClassNumerical = ClassNumerical.squeeze()"
      ],
      "metadata": {
        "id": "HtRcPMj_Hpyt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import scipy.stats as stats\n",
        "\n",
        "# Define Dataframe\n",
        "dfGA = df.iloc[: , 1:]\n",
        "# Calculate the z-score from with scipy\n",
        "dfGA = dfGA.select_dtypes(include='number').apply(stats.zscore)\n",
        "dataframe = pd.concat([dfGA, pd.DataFrame(ClassNumerical)], axis=1)"
      ],
      "metadata": {
        "id": "h-GwbIwD9DRH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # Create the model\n",
        "# model = Sequential()\n",
        "# model.add(Dense(64, input_dim=dfGA.shape[1], activation='relu'))\n",
        "# model.add(Dense(32, activation='relu'))\n",
        "# model.add(Dense(1, activation='sigmoid'))\n",
        "  \n",
        "# model.compile(loss='binary_crossentropy', optimizer='rmsprop', metrics=['accuracy'])\n",
        "# # Generate dataframes for both training and testing\n",
        "# X_train, X_test, y_train, y_test = generate_dataframes_for_training(dataframe)\n",
        "# X_train = np.asarray(X_train).astype('float32')\n",
        "# X_test = np.asarray(X_test).astype('float32')\n",
        "# y_train = np.asarray(y_train).astype('float32')\n",
        "# y_test = np.asarray(y_test).astype('float32')"
      ],
      "metadata": {
        "id": "rq-t4Lrf8nQW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# start = time.time()\n",
        "# model.fit(X_train, y_train, epochs=128, verbose=0)\n",
        "# print('Time elapsed for training the model with the full dataset: ', time.time() - start, ' seconds')"
      ],
      "metadata": {
        "id": "DsCOYkFzArN9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# pred = model.predict(X_test)\n",
        "# print('Recall: ', recall_fun(y_test, pred.round()))\n",
        "# print('Precision: ', precision_fun(y_test, pred.round()))\n",
        "# print('F1 Score: ', f1_fun(y_test, pred.round()))"
      ],
      "metadata": {
        "id": "wjacNvllBFKK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "start = time.time()\n",
        "final_population, fitness_accuracy = main_loop(200, dataframe, max_iter = 10, verbose=True)\n",
        "print('Time elapsed for executing the recursive GA: ', time.time() - start, ' seconds')"
      ],
      "metadata": {
        "id": "hdPPKx9d7S5W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "featuresGAall = pd.DataFrame(features).transpose()\n",
        "selected_featuresGA = featuresGAall.loc[:, [True if char == '1' else False for char in final_population]]\n",
        "selected_featuresGA"
      ],
      "metadata": {
        "id": "kZ1tA6Pn7XM-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "optimized_dataframe = dataframe.loc[:, [True if char == '1' else False for char in final_population+'0']]\n",
        "optimized_dataframe['Class'] = dataframe['Class']\n",
        "\n",
        "# Drop last column\n",
        "optimized_dataframe.drop(columns=df.columns[-1], \n",
        "        axis=1, \n",
        "        inplace=True)\n",
        "\n",
        "importances = mutual_info_classif(optimized_dataframe, ClassNumerical)\n",
        "\n",
        "mutual_info = pd.Series(importances)\n",
        "mutual_info.index = optimized_dataframe.columns\n",
        "mutual_info.sort_values(ascending=False, inplace = True)\n",
        "k = 100\n",
        "bestkfeatures = mutual_info[0:k]\n",
        "\n",
        "feat_importances = pd.Series(bestkfeatures, optimized_dataframe.columns[0:len(optimized_dataframe.columns)])\n",
        "feat_importances.plot(kind='barh',color = 'teal')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "O3gF1Z2bVtkW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "infogainGA = pd.DataFrame(feat_importances)\n",
        "infogainGA.columns = ['value']\n",
        "infogainGA.sort_values(by=['value'],ascending=False,inplace=True)\n",
        "infogainGA = infogainGA.transpose()\n",
        "infogainGA.transpose()\n",
        "infogainGA"
      ],
      "metadata": {
        "id": "ZG0kTYIAdjXr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "optimized_dataframe['Class'] = dataframe['Class']\n",
        "outname = task+'_GA_IG.xlsx'\n",
        "outname2 = task+'_GA_IG_Rank.xlsx'\n",
        "outGA = os.path.join(outpath,outname)\n",
        "outGA2 = os.path.join(outpath,outname2)\n",
        "optimized_dataframe.to_excel(outGA)\n",
        "infogainGA.to_excel(outGA2)"
      ],
      "metadata": {
        "id": "NI-Ftl4btDc_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# optimized_dataframe = dataframe.loc[:, [True if char == '1' else False for char in final_population+'0']]\n",
        "# optimized_dataframe['Class'] = dataframe['Class']\n",
        "# # Create the model\n",
        "# model = Sequential()\n",
        "# model.add(Dense(64, input_dim=optimized_dataframe.shape[1], activation='relu'))\n",
        "# model.add(Dense(32, activation='relu'))\n",
        "# model.add(Dense(1, activation='sigmoid'))\n",
        "  \n",
        "# model.compile(loss='binary_crossentropy', optimizer='rmsprop', metrics=['accuracy'])\n",
        "# # Generate dataframes for both training and testing\n",
        "# X_train, X_test, y_train, y_test = generate_dataframes_for_training(optimized_dataframe)\n",
        "# X_train = np.asarray(X_train).astype('float32')\n",
        "# X_test = np.asarray(X_test).astype('float32')\n",
        "# y_train = np.asarray(y_train).astype('float32')\n",
        "# y_test = np.asarray(y_test).astype('float32')"
      ],
      "metadata": {
        "id": "Kz2juJTnBeNf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# start = time.time()\n",
        "# model.fit(X_train, y_train, epochs=128, verbose=0)\n",
        "# print('Time elapsed for training the model with the full dataset: ', time.time() - start, ' seconds')"
      ],
      "metadata": {
        "id": "nCN84tXTBhqQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# print('Recall: ', recall_fun(y_test, pred.round()))\n",
        "# print('Precision: ', precision_fun(y_test, pred.round()))\n",
        "# print('F1 Score: ', f1_fun(y_test, pred.round()))"
      ],
      "metadata": {
        "id": "QWPbNFfyBjH2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "n5VT0BqL2hy7"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}