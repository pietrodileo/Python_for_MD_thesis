{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/pietrodileo/Python_for_MD_thesis/blob/main/TrainCNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5D_LUG6ajBr6"
      },
      "source": [
        "# 1. 🚀 Install, Import, Login"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k4dCH_UCpzF6"
      },
      "source": [
        "Setup for W&B Tool"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 539,
      "metadata": {
        "id": "EF0A0Yd4dQw6"
      },
      "outputs": [],
      "source": [
        "# Install a pip package in the current Jupyter kernel\n",
        "# import sys\n",
        "# !{sys.executable} -m pip install wandb\n",
        "# import wandb\n",
        "# from wandb.keras import WandbCallback\n",
        "## 075552994aad288a1162d4ab06f96040112fd54c\n",
        "# wandb.login()\n",
        "\n",
        "# wandb.init()\n",
        "# config = wandb.config"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QICVulkAp2WH"
      },
      "source": [
        "Import Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 640,
      "metadata": {
        "id": "Rzb8hEseZL0d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 353
        },
        "outputId": "9c59256c-0acc-4945-d00e-bf4c606aa6d8"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-640-ca5353b9da68>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mplotly\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph_objects\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mgo\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mplotly\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubplots\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmake_subplots\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0maspose\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwords\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0maw\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'aspose'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "import wave\n",
        "import pylab\n",
        "import sys\n",
        "from pathlib import Path\n",
        "from scipy import signal\n",
        "from scipy.io import wavfile\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from keras.utils.vis_utils import plot_model\n",
        "import itertools\n",
        "import time\n",
        "import shutil\n",
        "import plotly.express as px\n",
        "import plotly.graph_objects as go\n",
        "from plotly.subplots import make_subplots"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install aspose-words\n",
        "import aspose.words as aw"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pd-3ktNDEWpn",
        "outputId": "1721ec67-793e-451e-c2f2-d3543ae8ca5f"
      },
      "execution_count": 642,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: aspose-words in /usr/local/lib/python3.7/dist-packages (22.10.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# To save static image with plotly\n",
        "%%capture\n",
        "!pip install kaleido\n",
        "!pip install plotly>=4.0.0\n",
        "!wget https://github.com/plotly/orca/releases/download/v1.2.1/orca-1.2.1-x86_64.AppImage -O /usr/local/bin/orca\n",
        "!chmod +x /usr/local/bin/orca\n",
        "!apt-get install xvfb libgtk2.0-0 libgconf-2-4"
      ],
      "metadata": {
        "id": "TsQWNv1D9eeK"
      },
      "execution_count": 631,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lh3M28Qsp4qf"
      },
      "source": [
        "Calculate execution time"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 580,
      "metadata": {
        "id": "5wRUqDOupwVY"
      },
      "outputs": [],
      "source": [
        "start_time = time.time()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0-Kj8LW0Pll-"
      },
      "source": [
        "## 2. Preparing the data\n",
        "We can now load the spectrograms into memory. We use the image_dataset_from_directory utility to generate the datasets, and we use Keras image preprocessing layers for image standardization and data augmentation. The validation set is what will ultimately be our benchmark when becomes to performance and accuracy of our classifier. The batch size is set fairly low for now (32) for all images to fit in memory. The seed is for reproducibility."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 581,
      "metadata": {
        "id": "oM3R5Fh0PIbK"
      },
      "outputs": [],
      "source": [
        "def createTrain_and_Test_Dataset(directory,BATCH_SIZE,VAL_SPLIT,IMAGE_HEIGHT, IMAGE_WIDTH, MODE):\n",
        "  # Make a dataset containing the training spectrograms\n",
        "  train_dataset = tf.keras.preprocessing.image_dataset_from_directory(\n",
        "                                            directory,\n",
        "                                            labels='inferred',\n",
        "                                            batch_size=BATCH_SIZE,\n",
        "                                            validation_split=VAL_SPLIT,\n",
        "                                            subset='training',\n",
        "                                            shuffle=True,\n",
        "                                            color_mode= MODE,\n",
        "                                            image_size=(IMAGE_HEIGHT, IMAGE_WIDTH),\n",
        "                                            seed=0)\n",
        "\n",
        "  # Make a dataset containing the validation spectrogram\n",
        "  valid_dataset = tf.keras.preprocessing.image_dataset_from_directory(\n",
        "                                            directory,\n",
        "                                            labels='inferred',\n",
        "                                            batch_size=BATCH_SIZE,\n",
        "                                            validation_split=VAL_SPLIT,\n",
        "                                            subset='validation',\n",
        "                                            shuffle=True,\n",
        "                                            color_mode= MODE,\n",
        "                                            image_size=(IMAGE_HEIGHT, IMAGE_WIDTH),\n",
        "                                            seed=0)\n",
        "  return train_dataset, valid_dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xHtsnmb6Prhi"
      },
      "source": [
        "Before we can build our model and start training, we need to apply one simple augmentation the dataset and that is rescaling. We convert input from int to float32 and rescale it from the (0, 255) range to the (0,1) range."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 582,
      "metadata": {
        "id": "DU_FcEUaP26F"
      },
      "outputs": [],
      "source": [
        "# Function to prepare our datasets for modelling\n",
        "def prepare(ds, augment=False):\n",
        "    # Define our one transformation\n",
        "    rescale = tf.keras.Sequential([tf.keras.layers.experimental.preprocessing.Rescaling(1./255)])\n",
        "    \n",
        "    flip_and_rotate = tf.keras.Sequential([\n",
        "        tf.keras.layers.experimental.preprocessing.RandomFlip(\"horizontal_and_vertical\"),\n",
        "        tf.keras.layers.experimental.preprocessing.RandomRotation(0.2)\n",
        "    ])\n",
        "\n",
        "    # Apply rescale to both datasets and augmentation only to training\n",
        "    ds = ds.map(lambda x, y: (rescale(x, training=True), y))\n",
        "    # if augment == True, do ImageAugmentation\n",
        "    if augment: \n",
        "      ds = ds.map(lambda x, y: (flip_and_rotate(x, training=True), y))\n",
        "    return ds"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I-L4Yt1djL5g"
      },
      "source": [
        "# 2. 🧠 Define the Model and Train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 583,
      "metadata": {
        "id": "5F8bXADMjRZi"
      },
      "outputs": [],
      "source": [
        "def make_model(IMAGE_HEIGHT, IMAGE_WIDTH, N_CHANNELS, N_CLASSES):\n",
        "  # Create CNN model with 3 Convolution Layer Architecture\n",
        "  model = tf.keras.models.Sequential()\n",
        "  model.add(tf.keras.layers.Input(shape=(IMAGE_HEIGHT, IMAGE_WIDTH, N_CHANNELS)))\n",
        "  # Conv2D(NumFilter, FilterSize, option...)\n",
        "  model.add(tf.keras.layers.Conv2D(32, (3, 3), strides=2, padding='same', activation='relu')) #kernel_initializer='he_uniform'\n",
        "  #model.add(tf.keras.layers.BatchNormalization())\n",
        "  model.add(tf.keras.layers.MaxPooling2D(pool_size=(2, 2)))\n",
        "  #model.add(tf.keras.layers.BatchNormalization())\n",
        "  model.add(tf.keras.layers.Conv2D(64, (3, 3), padding='same', activation='relu'))\n",
        "  #model.add(tf.keras.layers.BatchNormalization())\n",
        "  model.add(tf.keras.layers.MaxPooling2D(pool_size=(2, 2)))\n",
        "  #model.add(tf.keras.layers.BatchNormalization())\n",
        "  model.add(tf.keras.layers.Conv2D(128, (3, 3), padding='same', activation='relu'))\n",
        "  #model.add(tf.keras.layers.BatchNormalization())\n",
        "  model.add(tf.keras.layers.MaxPooling2D(pool_size=(2, 2)))\n",
        "  #model.add(tf.keras.layers.BatchNormalization())\n",
        "  model.add(tf.keras.layers.Flatten())\n",
        "  model.add(tf.keras.layers.Dense(256, activation='relu')) \n",
        "  #model.add(tf.keras.layers.BatchNormalization())\n",
        "  #model.add(tf.keras.layers.Dropout(0.5))\n",
        "  model.add(tf.keras.layers.Dense(N_CLASSES, activation='softmax'))\n",
        "  return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 584,
      "metadata": {
        "id": "_uV7Gp_1QDJi"
      },
      "outputs": [],
      "source": [
        "# def plotResults(history,SaveFile,outputPath):\n",
        "#   # Plot the loss curves for training and validation.\n",
        "#   history_dict = history.history\n",
        "#   loss_values = history_dict['loss']\n",
        "#   val_loss_values = history_dict['val_loss']\n",
        "#   epochs = range(1, len(loss_values)+1)\n",
        "\n",
        "#   plt.figure(figsize=(10,15))\n",
        "#   plt.subplot(211)\n",
        "#   plt.plot(epochs, loss_values, 'g', label='Training loss')\n",
        "#   plt.plot(epochs, loss_values, 'go')\n",
        "#   plt.plot(epochs, val_loss_values, 'b', label='Validation loss')\n",
        "#   plt.plot(epochs, val_loss_values, 'bo')\n",
        "#   plt.title('Training and validation loss')\n",
        "#   plt.xlabel('Epochs')\n",
        "#   plt.ylabel('Loss')\n",
        "#   plt.legend()\n",
        "#   plt.show()\n",
        "\n",
        "#   # Plot the accuracy curves for training and validation.\n",
        "#   acc_values = history_dict['accuracy']\n",
        "#   val_acc_values = history_dict['val_accuracy']\n",
        "#   epochs = range(1, len(acc_values)+1)\n",
        "\n",
        "#   plt.figure(figsize=(10,15))\n",
        "#   plt.subplot(221)\n",
        "#   plt.plot(epochs, acc_values, 'g', label='Training accuracy')\n",
        "#   plt.plot(epochs, acc_values, 'go')\n",
        "#   plt.plot(epochs, val_acc_values, 'b', label='Validation accuracy')\n",
        "#   plt.plot(epochs, val_acc_values, 'bo')\n",
        "#   plt.title('Training and validation accuracy')\n",
        "#   plt.xlabel('Epochs')\n",
        "#   plt.ylabel('Accuracy')\n",
        "#   plt.legend()\n",
        "#   plt.show()\n",
        "\n",
        "#   if SaveFile == True:\n",
        "#     AccLossPngOutput = os.path.join(outputPath,'results.png')\n",
        "#     plt.savefig(AccLossPngOutput, bbox_inches='tight')\n",
        "#     plt.close()\n",
        "#     print('Image Saved')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def plotResults(history,SaveFile,outputPath):\n",
        "  # Plot the loss curves for training and validation.\n",
        "  history_dict = history.history\n",
        "  loss_values = history_dict['loss']\n",
        "  val_loss_values = history_dict['val_loss']\n",
        "  epochs = range(1, len(loss_values)+1)\n",
        "  \n",
        "  d = {'Train Loss': loss_values, 'Test Loss': val_loss_values, 'Epochs':epochs}\n",
        "  df = pd.DataFrame(d)\n",
        "  \n",
        "  fig = go.Figure()\n",
        "  fig = make_subplots(rows=2, cols=1,\n",
        "                      subplot_titles=(\"Training and Validation Loss\", \"Training and Validation Accuracy\"))\n",
        "\n",
        "  fig.append_trace(go.Scatter(\n",
        "      x=df['Epochs'],\n",
        "      y=df['Train Loss'],\n",
        "      name=\"Training Loss\",       # this sets its legend entry\n",
        "      mode='lines+markers'\n",
        "  ),1,1),\n",
        "\n",
        "  fig.append_trace(go.Scatter(\n",
        "      x=df['Epochs'],\n",
        "      y=df['Test Loss'],\n",
        "      name=\"Validation Loss\",\n",
        "      mode='lines+markers'\n",
        "  ),1,1),\n",
        "\n",
        "  # Plot the accuracy curves for training and validation.\n",
        "  acc_values = history_dict['accuracy']\n",
        "  val_acc_values = history_dict['val_accuracy']\n",
        "  epochs = range(1, len(acc_values)+1)\n",
        "\n",
        "  d = {'Train Accuracy': acc_values, 'Test Accuracy': val_acc_values, 'Epochs':epochs}\n",
        "  df = pd.DataFrame(d)\n",
        "\n",
        "  fig.append_trace(go.Scatter(\n",
        "      x=df['Epochs'],\n",
        "      y=df['Train Accuracy'],\n",
        "      name=\"Training Accuracy\",       # this sets its legend entry\n",
        "      mode='lines+markers'\n",
        "  ),2,1),\n",
        "\n",
        "  fig.append_trace(go.Scatter(\n",
        "      x=df['Epochs'],\n",
        "      y=df['Test Accuracy'],\n",
        "      name=\"Validation Accuracy\",\n",
        "      mode='lines+markers'\n",
        "  ),2,1),\n",
        "\n",
        "  # edit axis labels\n",
        "  fig['layout']['xaxis']['title']='Epochs'\n",
        "  fig['layout']['xaxis2']['title']='Epochs'\n",
        "  fig['layout']['yaxis']['title']='Loss'\n",
        "  fig['layout']['yaxis2']['title']='Accuracy'\n",
        "\n",
        "  # Tick Distance\n",
        "  fig['layout']['xaxis']['dtick']= 5\n",
        "  fig['layout']['xaxis2']['dtick']= 5\n",
        "  # First value on x axis\n",
        "  fig['layout']['xaxis']['tick0']= 0\n",
        "  fig['layout']['xaxis2']['tick0']= 0\n",
        "  # Tick Mode\n",
        "  fig['layout']['xaxis']['tickmode']= 'linear'\n",
        "  fig['layout']['xaxis2']['tickmode']= 'linear'\n",
        "\n",
        "  fig.update_layout(\n",
        "      height=800, \n",
        "      width=1200,\n",
        "      title=\"Loss and Accuracy\",\n",
        "      legend_title=\"Dataset\",\n",
        "      font=dict(size=14)\n",
        "  )\n",
        "\n",
        "  return fig, loss_values, val_loss_values, acc_values, val_acc_values"
      ],
      "metadata": {
        "id": "RpGQiSXAqHFw"
      },
      "execution_count": 609,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mt_EXMHB1aoy"
      },
      "source": [
        "# 3. 💯 Compute Code"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z64G6e4vSboI"
      },
      "source": [
        "Define Input and Output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 602,
      "metadata": {
        "id": "4cYlgi69qoJz"
      },
      "outputs": [],
      "source": [
        "TASK = '30epoche_NO_Batch_NO_Dropout_specProva'\n",
        "directory = '/content/drive/MyDrive/DatasetTesi/outputSpectrogram/Spectrogram/prova'\n",
        "outputPath = '/content/drive/MyDrive/DatasetTesi/outputSpectrogram/Spectrogram/Risultati'\n",
        "outputPath = os.path.join(outputPath,TASK)\n",
        "\n",
        "if not os.path.exists(outputPath):\n",
        "   # Create a new directory because it does not exist\n",
        "   os.makedirs(outputPath)\n",
        "   print(\"The output folder has been created!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6v7ePYXsSfCp"
      },
      "source": [
        "Define Parameters for Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 603,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NEzN4dZhSeFV",
        "outputId": "da9be7e5-8d99-4ef8-eab0-2741e5e1df34"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 227 files belonging to 2 classes.\n",
            "Using 182 files for training.\n",
            "Found 227 files belonging to 2 classes.\n",
            "Using 45 files for validation.\n"
          ]
        }
      ],
      "source": [
        "# Declare constants\n",
        "IMAGE_HEIGHT = 256\n",
        "IMAGE_WIDTH = 256\n",
        "BATCH_SIZE = 32\n",
        "N_CHANNELS = 3\n",
        "EPOCHS = 5 \n",
        "VAL_SPLIT = 0.2\n",
        "MODE = 'rgb'\n",
        "SaveFile = True\n",
        "\n",
        "[train_dataset, valid_dataset] = createTrain_and_Test_Dataset(directory,BATCH_SIZE,VAL_SPLIT,IMAGE_HEIGHT, IMAGE_WIDTH, MODE)\n",
        "\n",
        "classNames = train_dataset.class_names\n",
        "N_CLASSES = len(classNames)\n",
        "\n",
        "train_dataset = prepare(train_dataset, augment=False)\n",
        "valid_dataset = prepare(valid_dataset, augment=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ELEmc60XS1m-"
      },
      "source": [
        "Make Model and Plot Results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 604,
      "metadata": {
        "id": "sjKWPceKkTFb",
        "outputId": "7a4674c8-ceaa-4565-fb23-aa71bef73c65",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "6/6 [==============================] - 21s 2s/step - loss: 6.2392 - accuracy: 0.5275 - val_loss: 0.6827 - val_accuracy: 0.6889\n",
            "Epoch 2/5\n",
            "6/6 [==============================] - 17s 2s/step - loss: 0.6994 - accuracy: 0.5659 - val_loss: 0.6684 - val_accuracy: 0.5556\n",
            "Epoch 3/5\n",
            "6/6 [==============================] - 17s 2s/step - loss: 0.6745 - accuracy: 0.6264 - val_loss: 0.6242 - val_accuracy: 0.7111\n",
            "Epoch 4/5\n",
            "6/6 [==============================] - 20s 2s/step - loss: 0.6734 - accuracy: 0.5934 - val_loss: 0.6321 - val_accuracy: 0.6000\n",
            "Epoch 5/5\n",
            "6/6 [==============================] - 20s 2s/step - loss: 0.6584 - accuracy: 0.5604 - val_loss: 0.6168 - val_accuracy: 0.7111\n"
          ]
        }
      ],
      "source": [
        "# wandb.config = {\n",
        "#   \"learning_rate\": 0.001,\n",
        "#   \"epochs\": EPOCHS,\n",
        "#   \"batch_size\": BATCH_SIZE,\n",
        "#   \"architecture\": \"CNN\"\n",
        "# }\n",
        "\n",
        "model = make_model(IMAGE_HEIGHT, IMAGE_WIDTH, N_CHANNELS, N_CLASSES)\n",
        "\n",
        "# Compile model\n",
        "model.compile(\n",
        "    loss='sparse_categorical_crossentropy',\n",
        "    optimizer=tf.keras.optimizers.RMSprop(),\n",
        "    metrics=['accuracy'],\n",
        ")\n",
        "\n",
        "# wandb.init()\n",
        "\n",
        "# Train model and capture the history\n",
        "history = model.fit(train_dataset, epochs=EPOCHS, validation_data=valid_dataset)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "fig, loss_values, val_loss_values, acc_values, val_acc_values = plotResults(history,SaveFile,outputPath)\n",
        "fig.show()"
      ],
      "metadata": {
        "id": "GcZCdu8qoXdd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 817
        },
        "outputId": "09695744-b1e2-4d2d-c824-7e27533dca7f"
      },
      "execution_count": 633,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script src=\"https://cdn.plot.ly/plotly-2.8.3.min.js\"></script>                <div id=\"3005f7ba-3de2-46ed-b878-7dcaf97eca85\" class=\"plotly-graph-div\" style=\"height:800px; width:1200px;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"3005f7ba-3de2-46ed-b878-7dcaf97eca85\")) {                    Plotly.newPlot(                        \"3005f7ba-3de2-46ed-b878-7dcaf97eca85\",                        [{\"mode\":\"lines+markers\",\"name\":\"Training Loss\",\"x\":[1,2,3,4,5],\"y\":[6.239175319671631,0.6994141936302185,0.6744911074638367,0.6734368801116943,0.658358633518219],\"type\":\"scatter\",\"xaxis\":\"x\",\"yaxis\":\"y\"},{\"mode\":\"lines+markers\",\"name\":\"Validation Loss\",\"x\":[1,2,3,4,5],\"y\":[0.6826726198196411,0.668412983417511,0.6241937279701233,0.632142961025238,0.616759181022644],\"type\":\"scatter\",\"xaxis\":\"x\",\"yaxis\":\"y\"},{\"mode\":\"lines+markers\",\"name\":\"Training Accuracy\",\"x\":[1,2,3,4,5],\"y\":[0.5274725556373596,0.5659340620040894,0.6263736486434937,0.593406617641449,0.5604395866394043],\"type\":\"scatter\",\"xaxis\":\"x2\",\"yaxis\":\"y2\"},{\"mode\":\"lines+markers\",\"name\":\"Validation Accuracy\",\"x\":[1,2,3,4,5],\"y\":[0.6888889074325562,0.5555555820465088,0.7111111283302307,0.6000000238418579,0.7111111283302307],\"type\":\"scatter\",\"xaxis\":\"x2\",\"yaxis\":\"y2\"}],                        {\"template\":{\"data\":{\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"choropleth\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"choropleth\"}],\"contour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"contour\"}],\"contourcarpet\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"contourcarpet\"}],\"heatmap\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmap\"}],\"heatmapgl\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmapgl\"}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"histogram2d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2d\"}],\"histogram2dcontour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2dcontour\"}],\"mesh3d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"mesh3d\"}],\"parcoords\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"parcoords\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}],\"scatter\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatter\"}],\"scatter3d\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatter3d\"}],\"scattercarpet\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattercarpet\"}],\"scattergeo\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergeo\"}],\"scattergl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergl\"}],\"scattermapbox\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattermapbox\"}],\"scatterpolar\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolar\"}],\"scatterpolargl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolargl\"}],\"scatterternary\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterternary\"}],\"surface\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"surface\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}]},\"layout\":{\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"autotypenumbers\":\"strict\",\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]],\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]},\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"geo\":{\"bgcolor\":\"white\",\"lakecolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"showlakes\":true,\"showland\":true,\"subunitcolor\":\"white\"},\"hoverlabel\":{\"align\":\"left\"},\"hovermode\":\"closest\",\"mapbox\":{\"style\":\"light\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"bgcolor\":\"#E5ECF6\",\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"ternary\":{\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"bgcolor\":\"#E5ECF6\",\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"title\":{\"x\":0.05},\"xaxis\":{\"automargin\":true,\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"zerolinewidth\":2},\"yaxis\":{\"automargin\":true,\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"zerolinewidth\":2}}},\"xaxis\":{\"anchor\":\"y\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"Epochs\"},\"dtick\":5,\"tick0\":0,\"tickmode\":\"linear\"},\"yaxis\":{\"anchor\":\"x\",\"domain\":[0.625,1.0],\"title\":{\"text\":\"Loss\"}},\"xaxis2\":{\"anchor\":\"y2\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"Epochs\"},\"dtick\":5,\"tick0\":0,\"tickmode\":\"linear\"},\"yaxis2\":{\"anchor\":\"x2\",\"domain\":[0.0,0.375],\"title\":{\"text\":\"Accuracy\"}},\"annotations\":[{\"font\":{\"size\":16},\"showarrow\":false,\"text\":\"Training and Validation Loss\",\"x\":0.5,\"xanchor\":\"center\",\"xref\":\"paper\",\"y\":1.0,\"yanchor\":\"bottom\",\"yref\":\"paper\"},{\"font\":{\"size\":16},\"showarrow\":false,\"text\":\"Training and Validation Accuracy\",\"x\":0.5,\"xanchor\":\"center\",\"xref\":\"paper\",\"y\":0.375,\"yanchor\":\"bottom\",\"yref\":\"paper\"}],\"font\":{\"size\":14},\"height\":800,\"width\":1200,\"title\":{\"text\":\"Loss and Accuracy\"},\"legend\":{\"title\":{\"text\":\"Dataset\"}}},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('3005f7ba-3de2-46ed-b878-7dcaf97eca85');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Save pic in HTML\n",
        "if SaveFile == True:\n",
        "  AccLossPngOutput = os.path.join(outputPath,'results.html')\n",
        "  fig.write_html(AccLossPngOutput)\n",
        "  # Convert to PNG\n",
        "  AccLossPngOutputPNG = os.path.join(outputPath,'results.png')\n",
        "  \n",
        "  # Load an existing Word document\n",
        "  #doc = aw.Document(AccLossPngOutput)\n",
        "  # Specify image save options\n",
        "  # Set save format as PNG\n",
        "  #imageOptions = aw.saving.ImageSaveOptions(aw.SaveFormat.PNG)\n",
        "  # Save the pages as PNG\n",
        "  #doc.save(AccLossPngOutputPNG, imageOptions)\n",
        "  print('Image Saved')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wnMBGtUzDVHr",
        "outputId": "e5fd9c3e-acf4-4f19-d8c8-2e3fca88de67"
      },
      "execution_count": 650,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image Saved\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "psSaogYhS94c"
      },
      "source": [
        "Export Results to Google Drive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 595,
      "metadata": {
        "id": "jOmJcmE4eVTE"
      },
      "outputs": [],
      "source": [
        "# ⭐: log metrics using wandb.log\n",
        "# wandb.log({'epochs': EPOCHS,\n",
        "#            'loss': loss_values,\n",
        "#            'acc': acc_values, \n",
        "#            'val_loss': val_loss_values,\n",
        "#            'val_acc':val_acc_values})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 596,
      "metadata": {
        "id": "1wZf15D4QHVy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "52def4ee-f757-4633-d864-f28adb09a0eb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Final loss: 0.630254, final accuracy: 0.577778\n"
          ]
        }
      ],
      "source": [
        "# Compute the final loss and accuracy\n",
        "final_loss, final_acc = model.evaluate(valid_dataset, verbose=0)\n",
        "print(\"Final loss: {0:.6f}, final accuracy: {1:.6f}\".format(final_loss, final_acc))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 597,
      "metadata": {
        "id": "kGIMxaGmYvsM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e3df8b89-a50a-4d86-992d-8f3f0f00bf2b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Runtime:\n",
            "--- 450.9752106666565 seconds ---\n",
            "--- 7.516253511110942 minutes ---\n"
          ]
        }
      ],
      "source": [
        "runtime = time.time() - start_time\n",
        "\n",
        "print('Runtime:')\n",
        "print(\"--- %s seconds ---\" % (runtime))\n",
        "print(\"--- %s minutes ---\" % ((runtime)/60))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 598,
      "metadata": {
        "id": "68lcys2S5p9E"
      },
      "outputs": [],
      "source": [
        "# dictionary of lists  \n",
        "InfoDict = {'IMAGE_HEIGHT':[IMAGE_HEIGHT], 'IMAGE_WIDTH':[IMAGE_WIDTH],\n",
        "              'BATCH_SIZE': [BATCH_SIZE], 'N_CHANNELS': [N_CHANNELS], 'N_CLASSES': [N_CLASSES],\n",
        "              'EPOCHS':[EPOCHS], 'VAL_SPLIT': [VAL_SPLIT], 'MODE': MODE,\n",
        "              'FINAL VALIDATION LOSS': [final_loss], 'FINAL VALIDATION ACC': [final_acc],\n",
        "              'RUNTIME (s)': [runtime], 'RUNTIME (min)': [runtime/60]\n",
        "              }\n",
        "InfoDict\n",
        "dfInfo = pd.DataFrame(InfoDict)\n",
        "dfInfo.index = ['CNN']\n",
        "# saving the dataframe \n",
        "outputName = 'Model_Info_and_Performance.xlsx'\n",
        "OutputFileName = os.path.join(outputPath,outputName)\n",
        "if SaveFile == True:\n",
        "  # writing to Excel\n",
        "  dfInfo.to_excel(OutputFileName)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 637,
      "metadata": {
        "id": "g4K3KSjgzu7C"
      },
      "outputs": [],
      "source": [
        "# dictionary of lists  \n",
        "OutputDict = {'Train_ACC':acc_values, 'Train_LOSS':loss_values, \n",
        "              'Test_ACC': val_acc_values, 'Test_LOSS': val_loss_values}\n",
        "dfResult = pd.DataFrame(OutputDict) \n",
        "# saving the dataframe \n",
        "outputName = 'Risultati'\n",
        "OutputFileName = outputPath+'/'+outputName+'.xlsx'\n",
        "dfResult.to_excel(OutputFileName) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CJnUc6p7ll4Z"
      },
      "outputs": [],
      "source": [
        "Summary = os.path.join(outputPath,'modelsummary.txt')\n",
        "modelInfo = model.summary()\n",
        "\n",
        "stringlist = []\n",
        "model.summary(print_fn=lambda x: stringlist.append(x))\n",
        "short_model_summary = \"\\n\".join(stringlist)\n",
        "print(short_model_summary)\n",
        "\n",
        "with open(Summary, 'w') as f:\n",
        "  # Pass the file handle in as a lambda function to make it callable\n",
        "  f.write(short_model_summary)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FYy0getAmjMT"
      },
      "outputs": [],
      "source": [
        "pngOutput = os.path.join(outputPath,'model_plot.png')\n",
        "plot_model(model, to_file=pngOutput, show_shapes=True, show_layer_names=False)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "provenance": [],
      "mount_file_id": "1uPNwyh2BXmiKoSVMuiOKvsJ_AV9BbgoV",
      "authorship_tag": "ABX9TyPowuPmB3mXgX+GqqbAi/jI",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}